{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1V3VS85L1i6C"
   },
   "source": [
    "# Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "wy9U9E3kvRTK",
    "outputId": "f2fa9b49-a620-43cd-a3f8-5617bc2574f1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mG5xTy95vRV1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.chdir(\"/content/drive/My Drive/MS Thesis/Minimum Spanning Tree FAST\")\n",
    "os.chdir(\"/content/drive/My Drive/MS Thesis/FAST done In Home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "8oFBE1ndvYDh",
    "outputId": "967f8e94-57df-4369-e934-e8263bb62528"
   },
   "outputs": [],
   "source": [
    "!ls \"/content/drive/My Drive/MS Thesis/FAST done In Home\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uYDPPPvJwJsc"
   },
   "source": [
    "# Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "25ts2dUk1teJ",
    "outputId": "5a31c906-1660-4e59-fec2-0db09cd7160f"
   },
   "outputs": [],
   "source": [
    "pip install pyitlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FFk3wzQlwMti",
    "outputId": "a94d396f-b6b8-4a08-ebc4-6f9c98103c90"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.ensemble import RandomForestClassifier as RF, AdaBoostClassifier as AB\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ET\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GB\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize, StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# from scipy.stats import skew, kurtosis, iqr, median_absolute_deviation, entropy\n",
    "from scipy.stats import skew, kurtosis, iqr,  entropy\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from numpy.random import seed\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import networkx as nx\n",
    "from pyitlib import discrete_random_variable as drv\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import os\n",
    "import time\n",
    "from scipy.stats import chi2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import stats\n",
    "import random\n",
    "import pickle\n",
    "import ast\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.covariance import MinCovDet\n",
    "import scipy as sp\n",
    "import copy\n",
    "\n",
    "\n",
    "# from multiprocessing import Pool\n",
    "from multiprocess import Pool, Manager\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jyL1i55O2exr"
   },
   "source": [
    "# discritize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name =\"CCNC\"\n",
    "irrelevant_feature_storing_file_name = \"CCNC irrelevant feature\"\n",
    "per_fold_feature_storing_file_name = \"CCNC per fold feature\"\n",
    "myfile = open(output_file_name +\".txt\",\"w+\")\n",
    "irrelevant_feature_storing_file = open(irrelevant_feature_storing_file_name +\".txt\",\"w+\")\n",
    "per_fold_feature_storing_file = open(per_fold_feature_storing_file_name +\".txt\",\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretization_level = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekZkpmg91Kjf"
   },
   "outputs": [],
   "source": [
    "def get_discritized_df(df):\n",
    "  # t_df=undiscretized_df\n",
    "  t_df = df.copy()\n",
    "#   t_df.shape\n",
    "  class_df = t_df['0']\n",
    "  # print(class_df.shape)\n",
    "  # print (class_df.head(5))\n",
    "  feature_df = t_df.drop(columns=['0'])\n",
    "  feature_columns =list(feature_df.columns)\n",
    "#   print(feature_columns)\n",
    "#   columns.remove('0')\n",
    "#   print(columns)\n",
    "\n",
    "  # print(feature_df.shape)\n",
    "  # print (feature_df.head(3))\n",
    "  # print(undiscretized_df.shape, t_df.shape, feature_df.shape)\n",
    "  feature_values = feature_df.values.astype(float)\n",
    "  # print (feature_values.shape)\n",
    "  enc = KBinsDiscretizer(n_bins=discretization_level, encode='ordinal', strategy='uniform')\n",
    "  enc.fit(feature_values)\n",
    "  # feature_values = enc.transform(feature_values)\n",
    "  feature_values = enc.transform(feature_values).astype(np.int32)\n",
    "  # print (feature_values.shape)\n",
    "  # print (feature_values[0])\n",
    "  # numpy array of size 31x36\n",
    "  # pd.DataFrame(data=matrix,\n",
    "  #           index=np.array(range(1, 32)),\n",
    "  #           columns=np.array(range(1, 37)))\n",
    "  # new_feature_df = pd.DataFrame(data=feature_values, columns = [str(i) for i in range(1, len(undiscretized_df.columns))] )\n",
    "#   new_feature_df = pd.DataFrame(data=feature_values, columns = [str(i) for i in range(1, len(df.columns))] )\n",
    "  new_feature_df = pd.DataFrame(data=feature_values, columns = feature_columns )\n",
    "  # print(type(undiscretized_df))\n",
    "  # print(undiscretized_df.head(3))\n",
    "  # print(type(new_feature_df))\n",
    "  # print(new_feature_df.head(3))\n",
    "  discretized_df = pd.concat([class_df, new_feature_df], axis=1)\n",
    "#   print('in discretized_df')\n",
    "#   print('Original df shape ',df.shape)\n",
    "#   print(df.head(2))\n",
    "#   print('After discritizing df shape ',discretized_df.shape)\n",
    "#   print(discretized_df.head(2))\n",
    "  return discretized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_for_dataset_except_single_value_column(df):\n",
    "  t_df = df\n",
    "  class_df = t_df['0']\n",
    "\n",
    "  feature_df = t_df.drop(columns=['0'])\n",
    "  feature_columns =list(feature_df.columns)\n",
    "  \n",
    "  only_one_val_feature_list = []\n",
    "  new_feature_columns = feature_columns.copy()\n",
    "\n",
    "  for colum_name in feature_columns:\n",
    "    unique_val = np.unique(feature_df[colum_name].values).size\n",
    "    if unique_val == 1:\n",
    "      # only_one_val_feature_list.append(colum_name)\n",
    "      new_feature_columns.remove(colum_name)\n",
    "\n",
    "  new_feature_df = feature_df[ new_feature_columns ]\n",
    "  new_df = pd.concat([class_df, new_feature_df], axis=1)\n",
    "\n",
    "  return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # apply the min-max scaling in Pandas using the .min() and .max() methods\n",
    "# def get_min_max_normalized_df(df):\n",
    "#   # copy the dataframe\n",
    "#   df_norm = df.copy()\n",
    "#   # apply min-max scaling\n",
    "#   for column in df_norm.columns:\n",
    "#       df_norm[column] = (df_norm[column] - df_norm[column].min()) / (df_norm[column].max() - df_norm[column].min())\n",
    "      \n",
    "#   return df_norm\n",
    "    \n",
    "# # call the min_max_scaling function\n",
    "# # df_cars_normalized = min_max_scaling(df_cars)\n",
    "\n",
    "# # from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # # create a scaler object\n",
    "# # scaler = MinMaxScaler()\n",
    "# # # fit and transform the data\n",
    "# # df_norm = pd.DataFrame(scaler.fit_transform(df_cars), columns=df_cars.columns)\n",
    "\n",
    "# # df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {'0':[1, 0, 0, 0, 1, 0],\n",
    "#         'A1BG':[3.841, 4.414, 4.778, 4.019, 7.046, 6.419],\n",
    "#         'A2LD1':[6.299, 5.893, 5.219, 5.836, 7.142, 7.641],\n",
    "#         'A2M':[12.814, 13.103, 11.92, 10.871, 13.235, 12.169] }\n",
    "  \n",
    "# df = pd.DataFrame(data)\n",
    "# undiscretized_df = df\n",
    "# print(undiscretized_df)\n",
    "# discretized_df = get_discritized_df_for_plos_one(undiscretized_df)\n",
    "# print(discretized_df)\n",
    "# print(discretized_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "un_0MNKS-1Iv"
   },
   "source": [
    "# Get selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relevance_or_redundance_value_bias_corrected_without_normalization(df, feature1, feature2):\n",
    "    x_N = np.unique(df[feature1].values.astype(np.int32)).size\n",
    "    y_N = np.unique(df[feature2].values.astype(np.int32)).size\n",
    "    N = df.shape[0]\n",
    "    mi_bias_corrected = drv.information_mutual(df[feature1].values.astype(np.int32), df[feature2].values.astype(np.int32)) - ( ((x_N-1)*(y_N-1)) / (2*N*0.69314718056) )\n",
    "    return mi_bias_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_complementary_information_value_bias_corrected_without_normalization(df,feature1, feature2, class_label):\n",
    "    x_N = np.unique(df[feature1].values.astype(np.int32)).size\n",
    "    y_N = np.unique(df[feature2].values.astype(np.int32)).size\n",
    "    k_N = np.unique(df[class_label].values.astype(np.int32)).size\n",
    "    N = df.shape[0]\n",
    "    comp_mi_bias_corrected = drv.information_mutual_conditional(df[feature1].values.astype(np.int32), df[feature2].values.astype(np.int32), df[class_label].values.astype(np.int32)) - ( ((x_N-1) * (y_N-1) * k_N) / (2*N*0.69314718056) )\n",
    "    return comp_mi_bias_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval = .99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_critical_value(df, feature1, feature2, N):\n",
    "    ddf = (np.unique(df[feature1].values.astype(np.int32)).size - 1) * (np.unique(df[feature2].values.astype(np.int32)).size - 1)\n",
    "    value = chi2.ppf(confidence_interval, ddf)/ (2*N*0.69314718056)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_complementary_critical_value(df, feature1, feature2, class_label, N):\n",
    "    ddf = (np.unique(df[feature1].values.astype(np.int32)).size - 1) * (np.unique(df[feature2].values.astype(np.int32)).size - 1) * np.unique(df[class_label].values.astype(np.int32)).size\n",
    "    value = chi2.ppf(confidence_interval, ddf)/ (2*N*0.69314718056)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_critical_value_using_Rrc_criteria(df, candidate_feature, selected_feature_list, class_label, N):\n",
    "#     N = df.shape[0]\n",
    "    ddf_relevance = (np.unique(df[candidate_feature].values.astype(np.int32)).size - 1) * (np.unique(df[class_label].values.astype(np.int32)).size - 1)\n",
    "    ddf_redundance_list = []\n",
    "    ddf_complementary_list = []\n",
    "    \n",
    "    for feature in selected_feature_list:\n",
    "        ddf_redundance = (np.unique(df[candidate_feature].values.astype(np.int32)).size - 1) * (np.unique(df[feature].values.astype(np.int32)).size - 1)\n",
    "        ddf_complementary = (np.unique(df[candidate_feature].values.astype(np.int32)).size - 1) * (np.unique(df[feature].values.astype(np.int32)).size - 1) * np.unique(df[class_label].values.astype(np.int32)).size\n",
    "        ddf_redundance_list.append( ddf_redundance )\n",
    "        ddf_complementary_list.append( ddf_complementary )\n",
    "    \n",
    "    ddf = ddf_relevance + np.mean(np.array(ddf_complementary_list)) - np.mean(np.array(ddf_redundance_list))\n",
    "    Rrc_critical_value = chi2.ppf(confidence_interval, ddf)/ (2*N*0.69314718056)\n",
    "    \n",
    "    redundance_ddf = np.mean(np.array(ddf_redundance_list))\n",
    "    redundance_critical_value = chi2.ppf(confidence_interval, redundance_ddf)/ (2*N*0.69314718056)\n",
    "    \n",
    "    relevance_critical_value = chi2.ppf(confidence_interval, ddf_relevance)/ (2*N*0.69314718056)\n",
    "    return relevance_critical_value, redundance_critical_value, Rrc_critical_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8t4YRIE8BXWA"
   },
   "outputs": [],
   "source": [
    "def get_t_relevance_value_list(df, columns, class_label):\n",
    "  # m= number of features in the dataset\n",
    "  t_relevance = {}\n",
    "  relevance = {}\n",
    "  for i in range (len(columns)):\n",
    "    t_relevance[ (columns[i], class_label) ] = calculate_relevance_or_redundance_value_bias_corrected_without_normalization(df, columns[i], class_label)\n",
    "#     relevance[ (columns[i], class_label) ] = calculate_relevance_or_redundance_value_without_normalization(df, columns[i], class_label)\n",
    "  \n",
    "  return t_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_irrelevant_feature_using_t_relevance_critical_value(df,t_relevance):\n",
    "  N = df.shape[0]\n",
    "  selected_feature_subset = []\n",
    "  for key, value in t_relevance.items():\n",
    "    critical_val = calculate_critical_value(df, key[0], key[1], N)\n",
    "#     print(key, \" -->> Rel val : \", value, \" critical_val: \", critical_val, \" sample size \", N)\n",
    "    if value > critical_val :\n",
    "      feature_name = key[0]\n",
    "      # print(key, key[0])\n",
    "      selected_feature_subset.append(feature_name)\n",
    "  return selected_feature_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_feature_list(t_relevance, feature_list, class_label):\n",
    "    unsorted_feature_list = {}\n",
    "    for feature in feature_list:\n",
    "        unsorted_feature_list[feature] = t_relevance[(feature,class_label)]\n",
    "    sorted_feature_list = OrderedDict(sorted(unsorted_feature_list.items(),reverse=True, key=itemgetter(1)))\n",
    "    return sorted_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_JMI_Chi_value_bias_corrected_without_normalization(df, candidate_feature, selected_feature_list, class_label):\n",
    "    relevance_val = calculate_relevance_or_redundance_value_bias_corrected_without_normalization(df, candidate_feature, class_label)\n",
    "    redundance_list = []\n",
    "    complementary_list = []\n",
    "    for feature in selected_feature_list:\n",
    "        redundance_val = calculate_relevance_or_redundance_value_bias_corrected_without_normalization(df, candidate_feature, feature)\n",
    "        complementary_val = calculate_complementary_information_value_bias_corrected_without_normalization(df, candidate_feature, feature, class_label)\n",
    "        redundance_list.append( redundance_val )\n",
    "        complementary_list.append( complementary_val )\n",
    "    return relevance_val, np.mean(np.array(redundance_list)), ( relevance_val + np.mean(np.array(complementary_list)) - np.mean(np.array(redundance_list)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_pair(selected_feature_subset):\n",
    "  all_pair = []\n",
    "#   pair_dic dictionary to avoid both (1,2) and (2,1) computing\n",
    "#   it will add one tuple from (1,2) and (2,1) in all_pair_with_df\n",
    "#   in this case it will compute half feature pair\n",
    "  pair_dic ={}\n",
    "  for i in selected_feature_subset:\n",
    "    for j in selected_feature_subset:\n",
    "      if i != j :\n",
    "        if (j, i) in pair_dic:\n",
    "          pair_dic[ (i, j) ] = pair_dic[ (j, i) ]\n",
    "          continue\n",
    "        \n",
    "        pair = (i,j)\n",
    "        pair_dic[ (i, j) ] = 1\n",
    "        all_pair.append(pair)\n",
    "  \n",
    "  return all_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mi(pair):\n",
    "  global df_for_parallel\n",
    "  from pyitlib import discrete_random_variable as drv\n",
    "  import numpy as np\n",
    "\n",
    "  i, j = pair\n",
    "#   val = ( 2*drv.information_mutual(df_for_parallel[i].values.astype(np.int32), df_for_parallel[j].values.astype(np.int32)) ) / ( drv.entropy(df_for_parallel[i].values.astype(np.int32)) + drv.entropy(df_for_parallel[j].values.astype(np.int32)) )\n",
    "  x_N = np.unique(df_for_parallel[i].values.astype(np.int32)).size\n",
    "  y_N = np.unique(df_for_parallel[j].values.astype(np.int32)).size\n",
    "  N = df_for_parallel.shape[0]\n",
    "  mi_bias_corrected = drv.information_mutual(df_for_parallel[i].values.astype(np.int32), df_for_parallel[j].values.astype(np.int32)) - ( ((x_N-1)*(y_N-1)) / (2*N*0.69314718056) )\n",
    "  return (i,j), mi_bias_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initpool(discretized_df):\n",
    "  global df_for_parallel\n",
    "  df_for_parallel = discretized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_relevance_of_a_cluster(t_relevance, one_cluster_features, class_label):\n",
    "  relevance_val_list = []\n",
    "  for i in one_cluster_features:\n",
    "    relevance_val_list.append(t_relevance[(i, class_label)])\n",
    "  mean_relevance_val = np.mean(np.array(relevance_val_list))\n",
    "#   print(\"mean_relevance_val -> \", mean_relevance_val)\n",
    "  return mean_relevance_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_redundance_of_a_cluster(f_correlation, one_cluster_features):\n",
    "  redundance_val_list = []\n",
    "  for i in one_cluster_features:\n",
    "    for j in one_cluster_features:\n",
    "      if i != j :\n",
    "        redundance_val_list.append(f_correlation[(i, j)])\n",
    "  mean_redundance_val = np.mean(np.array(redundance_val_list))\n",
    "#   print(\"mean_redundance_val -> \", mean_redundance_val)\n",
    "  return mean_redundance_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_mean_redundance_of_left_and_right_cluster(f_correlation, left_side_cluster, right_side_cluster, root_cluster_length):\n",
    "  left_cluster_mean_redundance = 0\n",
    "  right_cluster_mean_redundance = 0\n",
    "  left_cluster_length = len(left_side_cluster)\n",
    "  right_cluster_length = len(right_side_cluster)\n",
    "#   left_plus_right_cluster_length = left_cluster_length + right_cluster_length\n",
    "\n",
    "  if left_cluster_length > 1 :\n",
    "    left_cluster_mean_redundance = ( left_cluster_length / root_cluster_length ) * calculate_mean_redundance_of_a_cluster(f_correlation, left_side_cluster)\n",
    "  if right_cluster_length > 1 :\n",
    "    right_cluster_mean_redundance = ( right_cluster_length / root_cluster_length ) * calculate_mean_redundance_of_a_cluster(f_correlation, right_side_cluster)\n",
    "\n",
    "  return left_cluster_mean_redundance, right_cluster_mean_redundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_dataframe_with_corresponding_class(df, class_list):\n",
    "  df_collection = {}\n",
    "  for class_id in class_list:\n",
    "    one_df = df.loc[ df['0'] == class_id ]\n",
    "    # print(\"class \", class_id, \" class id type \", type(class_id), type(one_df), one_df.shape[0])\n",
    "    # print(one_df)\n",
    "    df_collection[class_id] = one_df\n",
    "\n",
    "  return df_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dict_with_class_distance_list(class_list):\n",
    "  class_distance_list_dict = {}\n",
    "  for class_id in class_list:\n",
    "    class_distance_list_dict[class_id] = []\n",
    "  return class_distance_list_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Implementation with sklearn with hole list for dot product\n",
    "# # NSL KDD\n",
    "# from sklearn.covariance import MinCovDet\n",
    "# #Robust Mahalonibis Distance\n",
    "# def robust_mahalanobis_method(df):\n",
    "#   #Minimum covariance determinant\n",
    "#   rng = np.random.RandomState(0)\n",
    "#   real_cov = np.cov(df.values.T)\n",
    "# #   X = rng.multivariate_normal(mean=np.mean(df, axis=0), cov=real_cov, size=506)\n",
    "#   X = rng.multivariate_normal(mean=np.mean(df, axis=0), cov=real_cov, size=df.shape[0])\n",
    "#   cov = MinCovDet(random_state=0).fit(X)\n",
    "#   mcd = cov.covariance_ #robust covariance metric\n",
    "#   robust_mean = cov.location_  #robust mean\n",
    "#   inv_covmat = sp.linalg.inv(mcd) #inverse covariance metric\n",
    "\n",
    "#   # Split the dataframe\n",
    "#   distance_list = []\n",
    "#   df_list = np.array_split(df, 10)\n",
    "\n",
    "#   for one_df in df_list:\n",
    "#     #Robust M-Distance\n",
    "#     x_minus_mu = one_df - robust_mean\n",
    "#     left_term = np.dot(x_minus_mu, inv_covmat)\n",
    "#     mahal = np.dot(left_term, x_minus_mu.T)\n",
    "#     md = np.sqrt(mahal.diagonal())\n",
    "#     distance_list.extend(list(md))\n",
    "# #   print(len(distance_list),\"\\n\", distance_list)\n",
    "#   return distance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import MinCovDet\n",
    "#Robust Mahalonibis Distance\n",
    "def get_robust_mean_inverse_covariance_for_normal_attack_df(df):\n",
    "  #Minimum covariance determinant\n",
    "  rng = np.random.RandomState(42)\n",
    "  real_cov = np.cov(df.values.T)\n",
    "#   X = rng.multivariate_normal(mean=np.mean(df, axis=0), cov=real_cov, size=506)\n",
    "  X = rng.multivariate_normal(mean=np.mean(df, axis=0), cov=real_cov, size=df.shape[0])\n",
    "  cov = MinCovDet(random_state=42).fit(X)\n",
    "  mcd = cov.covariance_ #robust covariance metric\n",
    "  robust_mean = cov.location_  #robust mean\n",
    "  inv_covmat = sp.linalg.inv(mcd) #inverse covariance metric\n",
    "\n",
    "  return robust_mean, inv_covmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_robust_mean_list_inverse_covariance_list_for_normal_attack_df_from_resulting_clusters(df, final_clusters):\n",
    "  robust_mean_list = []\n",
    "  inv_covmat_list = []\n",
    "\n",
    "  for cluster in final_clusters:\n",
    "    print(\"Calculating Robust mean and covariamce of cluster -->> \", cluster)\n",
    "    if len(cluster) == 1:\n",
    "      robust_mean_list.append(0)\n",
    "      inv_covmat_list.append(0)\n",
    "    else:\n",
    "      robust_mean, inv_covmat = get_robust_mean_inverse_covariance_for_normal_attack_df(df[cluster])\n",
    "      robust_mean_list.append(robust_mean)\n",
    "      inv_covmat_list.append(inv_covmat)\n",
    "\n",
    "  return robust_mean_list, inv_covmat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_robust_mahalanobis_distance(df, robust_mean, inv_covmat):\n",
    "  # Split the dataframe\n",
    "  distance_list = []\n",
    "  df_list = np.array_split(df, 120)\n",
    "\n",
    "  c = 1\n",
    "  for one_df in df_list:\n",
    "#     print(\"Calculating RMD Chunk -->> \", c, \"/\", 10)\n",
    "    c = c+1\n",
    "    #Robust M-Distance\n",
    "    x_minus_mu = one_df - robust_mean\n",
    "    left_term = np.dot(x_minus_mu, inv_covmat)\n",
    "    mahal = np.dot(left_term, x_minus_mu.T)\n",
    "    md = np.sqrt(mahal.diagonal())\n",
    "    distance_list.extend(list(md))\n",
    "#   print(len(distance_list),\"\\n\", distance_list)\n",
    "  return distance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_derived_features_using_robust_mahalanobis_distance(df, final_clusters, robust_mean_list, inv_covmat_list):\n",
    "#   print(\"final_clusters are\\n\", final_clusters)\n",
    "  derived_feature_values =[]\n",
    "  list_of_no_of_features_in_each_cluster = []\n",
    "  c =0\n",
    "  for index, cluster in enumerate(final_clusters):\n",
    "    print(\"RMD is calculating for cluster \", (index+1), \"/\", len(final_clusters))\n",
    "#     print(cluster)\n",
    "    c = c+1\n",
    "    if len(cluster) == 1:\n",
    "      list_of_no_of_features_in_each_cluster.append(1)\n",
    "      derived_feature_values.append(list(df[cluster[0]].values))\n",
    "#       print(type(df[cluster].values), len(list(df[cluster].values)))\n",
    "    else:\n",
    "      md = get_robust_mahalanobis_distance(df[cluster], robust_mean_list[index], inv_covmat_list[index])\n",
    "#       md = calculate_robust_mahalanobis_method(df= df[cluster])\n",
    "      list_of_no_of_features_in_each_cluster.append(len(cluster))\n",
    "      derived_feature_values.append(list(md))\n",
    "#       print(type(md), len(list(md)))\n",
    "#     print(cluster)\n",
    "#   print(\"+++++++++++++++++++++++++++++++++\")\n",
    "#   print(np.array(derived_feature_values).shape)\n",
    "#   print(derived_feature_values)\n",
    "  \n",
    "  derived_features_df = pd.DataFrame(np.array(derived_feature_values).T)\n",
    "#   print(\"list_of_no_of_features_in_each_cluster: \", list_of_no_of_features_in_each_cluster)\n",
    "#   print(derived_features_df.shape, derived_features_df)\n",
    "  return list_of_no_of_features_in_each_cluster, derived_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_dicionary_ascending(f_correlation):\n",
    "  copied_f_correlation = copy.deepcopy(f_correlation)\n",
    "  return OrderedDict(sorted(copied_f_correlation.items(), key=itemgetter(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_list_from_dict(dict_val):\n",
    "#   for key, value in dict_val.iteritems():\n",
    "#     dictlist.append(temp)\n",
    "  \n",
    "  return list(dict_val.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_f_correlation_values(f_correlation, one_cluster_all_pair):\n",
    "  new_f_correlation = {}\n",
    "  for pair in one_cluster_all_pair:\n",
    "    new_f_correlation[pair] = f_correlation[pair]\n",
    "    \n",
    "  return new_f_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(f_correlation, key, one_cluster_features):\n",
    "  first_cluster = []\n",
    "  second_cluster = []\n",
    "  first_cluster.append(key[0])\n",
    "  second_cluster.append(key[1])\n",
    "  \n",
    "  remaining_feature_list = copy.deepcopy(one_cluster_features)\n",
    "  remaining_feature_list.remove(key[0])\n",
    "  remaining_feature_list.remove(key[1])\n",
    "\n",
    "  for feature in remaining_feature_list:\n",
    "    val1 = f_correlation[(key[0], feature)]\n",
    "    val2 = f_correlation[(key[1], feature)]\n",
    "    \n",
    "    if (val1 <= val2):\n",
    "      second_cluster.append(feature)\n",
    "    else:\n",
    "      first_cluster.append(feature)\n",
    "  \n",
    "  return first_cluster, second_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_to_get_final_feature_subset_RMD(df, actual_df, N, t_relevance, f_correlation, feature_list):\n",
    "  all_temporary_cluster = []\n",
    "  final_clusters = []\n",
    "  all_temporary_cluster.append( feature_list )\n",
    "  count = 1\n",
    "  \n",
    "  while len(all_temporary_cluster) is not 0 :\n",
    "    # Always take the first cluster for evaluation then remove it from the temporary cluster list\n",
    "    one_cluster_features = all_temporary_cluster[0]\n",
    "    all_temporary_cluster.remove(one_cluster_features)\n",
    "    print(\"ITERATION -->> \", count)\n",
    "    is_added_in_candidate_cluster = 0\n",
    "    \n",
    "    if ( len(one_cluster_features) == 1 ):\n",
    "      final_clusters.append(one_cluster_features)\n",
    "#       print(\"INCLUDED in final cluster (1 length cluster) -->> \", one_cluster_features, \"\\n==================================================\")\n",
    "      count += 1\n",
    "      continue\n",
    "    \n",
    "    one_cluster_all_pair = make_all_pair(one_cluster_features)\n",
    "    new_f_correlation = get_new_f_correlation_values(f_correlation, one_cluster_all_pair)\n",
    "    sorted_new_f_correlation = get_sorted_dicionary_ascending(new_f_correlation)\n",
    "    \n",
    "    root_cluster_length = len(one_cluster_features)\n",
    "    root_cluster_mean_redundance = calculate_mean_redundance_of_a_cluster(f_correlation, one_cluster_features)\n",
    "    cluster_evaluation_count = 5\n",
    "    \n",
    "    test_count = 1\n",
    "    for key, value in sorted_new_f_correlation.items():\n",
    "#       print(\"cluster_evaluation_count -->> \", test_count, \"of  Iteration -->> \", count)\n",
    "      \n",
    "      left_side_cluster, right_side_cluster = get_clusters(f_correlation, key, one_cluster_features)\n",
    "      \n",
    "#       root_cluster_length = len(one_cluster_features)\n",
    "#       root_cluster_mean_redundance = calculate_mean_redundance_of_a_cluster(f_correlation, one_cluster_features)\n",
    "      left_cluster_mean_redundance, right_cluster_mean_redundance = calculate_weighted_mean_redundance_of_left_and_right_cluster(f_correlation, left_side_cluster, right_side_cluster, root_cluster_length)\n",
    "      left_plus_right_cluster_mean_redundance = left_cluster_mean_redundance + right_cluster_mean_redundance    \n",
    "    \n",
    "      if (left_plus_right_cluster_mean_redundance > root_cluster_mean_redundance) :\n",
    "        diff = left_plus_right_cluster_mean_redundance - root_cluster_mean_redundance\n",
    "#         print(\"Child clusters redundance increased by -->> \", diff , ' from parent cluster')\n",
    "#         print(\"Left cluster ADDED IN TEMPORARY CLUSTER LIST\", left_side_cluster)\n",
    "#         print(\"Right clusterr ADDED IN TEMPORARY CLUSTER LIST \", right_side_cluster)\n",
    "        is_added_in_candidate_cluster = 1\n",
    "        all_temporary_cluster.append(left_side_cluster)\n",
    "        all_temporary_cluster.append(right_side_cluster)\n",
    "        break\n",
    "      \n",
    "      if (test_count == cluster_evaluation_count):\n",
    "        is_added_in_candidate_cluster = 1\n",
    "        final_clusters.append(one_cluster_features)\n",
    "#         print(\"INCLUDED in final cluster (from candidate cluster) -->> \", one_cluster_features,\"\\n==================================================\")\n",
    "#         print(\"cluster_evaluation_count -->> \", test_count, \"of  Iteration -->> \", count)\n",
    "        break\n",
    "      test_count += 1\n",
    "\n",
    "    \n",
    "    if (is_added_in_candidate_cluster == 0):\n",
    "      final_clusters.append(one_cluster_features)\n",
    "#       print(\"INCLUDED in final cluster (1 cluster all feature) -->> \", one_cluster_features,\"\\n==================================================\")\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "  print(\"NUMBER OF CLUSTER: \",len(final_clusters))\n",
    "#   myfile.write(\"NUMBER OF CLUSTER: \" + str(len(final_clusters)) + \"\\n\")\n",
    "  print(final_clusters)\n",
    "  \n",
    "  robust_mean_list, inv_covmat_list = get_robust_mean_list_inverse_covariance_list_for_normal_attack_df_from_resulting_clusters(actual_df, final_clusters)\n",
    "  \n",
    "  print(\"Length of robust_mean_list, inv_covmat_list, final_clusters \", len(robust_mean_list), len(inv_covmat_list), len(final_clusters))\n",
    "  return robust_mean_list, inv_covmat_list, final_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_selected_features_with_robust_mahalanobis_distance_with_actual_value(discretized_df, actual_df):\n",
    "  new_df= discretized_df.copy()\n",
    "  new_df = new_df.drop(columns='0')\n",
    "  columns =list(new_df.columns)\n",
    "  # print(\"Total Number of features \", len(columns))\n",
    "\n",
    "  t_relevance = get_t_relevance_value_list(discretized_df, columns, '0')\n",
    "  selected_feature_subset = remove_irrelevant_feature_using_t_relevance_critical_value(discretized_df, t_relevance)\n",
    "\n",
    "#   t_relevance, threshold_value = select_threshold_value_with_max_entropy_normalization_new(discretized_df, columns, '0')\n",
    "#   selected_feature_subset = remove_irrelevant_feature_using_t_relevance_critical_value_for_max_entropy_normalization_new(discretized_df, t_relevance)\n",
    "\n",
    "  print(\"T_relevance length is \", len(t_relevance))\n",
    "#   print('threshold value : ',threshold_value)\n",
    "\n",
    "  print(\"After removing irrelevant features using critical value \\nLength of selected subset feature length \", len(selected_feature_subset)) \n",
    "  myfile.write(\"After removing irrelevant features using critical value Length of selected subset feature length \"+ str(len(selected_feature_subset)) +\" and features are -->>\\n\" )\n",
    "  myfile.write( str(selected_feature_subset) + \"\\n\" )\n",
    "  irrelevant_feature_storing_file.write( str(selected_feature_subset) + \"\\n\" )\n",
    "#   print(selected_feature_subset)\n",
    "\n",
    "#   if len(selected_feature_subset) == 1:\n",
    "#     feature_score_dic = {}\n",
    "#     feature_score_dic[ selected_feature_subset[0] ] = t_relevance[ (selected_feature_subset[0] , '0') ]\n",
    "#     return selected_feature_subset, feature_score_dic\n",
    "\n",
    "  N = discretized_df.shape[0]\n",
    "  # Connected graph construction  \n",
    "#   G = nx.Graph()\n",
    "  f_correlation = {}\n",
    "  \n",
    "  print(\"Calculating F-correlation values -->>\")\n",
    "#   Connected graph construction time\n",
    "  connected_graph_start_time = time.time()\n",
    "  print(\"Creating All feature pair\")\n",
    "  all_pair = make_all_pair(selected_feature_subset)\n",
    "  print(\"All pair creation done\")\n",
    "\n",
    "#   pool = Pool(processes=(os.cpu_count()-1), initializer=initpool, initargs=(discretized_df,))\n",
    "  pool = Pool(processes=1, initializer=initpool, initargs=(discretized_df,))\n",
    "  print(\"Pool created\")\n",
    "  f_correlation_feature_pair_value_list = pool.map(calculate_mi, all_pair)\n",
    "  print(\"All f_correlation value calculation parallelly done and closing Pool -->>\")\n",
    "  pool.close()\n",
    "  pool.join()\n",
    "  print(\"Pool closed\")\n",
    "#   print(\"f_correlation_feature_pair_value_list length is :\",len(f_correlation_feature_pair_value_list))\n",
    "  for feature_pair_value in f_correlation_feature_pair_value_list:\n",
    "    feature_pair, value = feature_pair_value\n",
    "    reverse_feature_pair = feature_pair[::-1]\n",
    "    f_correlation[feature_pair] = value\n",
    "    f_correlation[reverse_feature_pair] = value\n",
    "  \n",
    "  connected_graph_end_time = time.time()\n",
    "  connected_graph_time_diff = connected_graph_end_time - connected_graph_start_time\n",
    "  print(\"All pair f_correlation value calculation time (PARALLELLY) is: \", connected_graph_time_diff, \"(sec) for (\", len(selected_feature_subset), \"*\",len(selected_feature_subset), \") dimension matrix\" )\n",
    "  myfile.write(\"All pair f_correlation value calculation time (PARALLELLY) is: \"+ str(connected_graph_time_diff) + \"\\n\")\n",
    "#   max_t_relevance_val, min_t_relevance_val = max(t_relevance.values()),min(t_relevance.values())\n",
    "#   max_relevance_val, min_relevance_val = max(relevance.values()),min(relevance.values())\n",
    "#   max_f_correlation_val, min_f_correlation_val = max(f_correlation.values()),min(f_correlation.values())\n",
    "# # #   max_redundance_val, min_redundance_val = max(redundance_val_dic.values()),min(redundance_val_dic.values())\n",
    "#   print(\"T-Relevance max, min -->> \",max_t_relevance_val, min_t_relevance_val)\n",
    "#   print(\"Relevance max, min -->> \",max_relevance_val, min_relevance_val)\n",
    "#   print(\"F-Correlation max, min -->> \",max_f_correlation_val, min_f_correlation_val)\n",
    "# # #   print(\"Redundant max, min -->> \", max_redundance_val, min_redundance_val)\n",
    "\n",
    "  print(\"f_correlation_feature_pair_value_list length is :\",len(f_correlation_feature_pair_value_list))\n",
    "  print(\"F-Correlation Length is -->> \",len(f_correlation))\n",
    "#   print(\"f_correlation_feature_pair_value_list length will be half of length f_correlation\")\n",
    "\n",
    "#   print(\"-------------t_relevance------------\\n\", t_relevance, \"\\n\")\n",
    "#   print(\"-------------f_correlation------------\\n\", f_correlation, \"\\n\")\n",
    "\n",
    "  robust_mean_list, inv_covmat_list, final_clusters = create_cluster_to_get_final_feature_subset_RMD(discretized_df, actual_df, N, t_relevance, f_correlation, selected_feature_subset)\n",
    "  \n",
    "  # print(\"final selected feature length is \",len(final_selected_feature_list))\n",
    "  # print(final_selected_feature_list)\n",
    "  f_correlation = {}\n",
    "  return robust_mean_list, inv_covmat_list, final_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2ASpDCC2YJO"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uKarf-kt2dOo"
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "saSD-byW3s-C"
   },
   "outputs": [],
   "source": [
    "def classification_report(cm):\n",
    "\n",
    "  true_pos = np.diag(cm)\n",
    "  false_pos = np.sum(cm, axis=0) - true_pos\n",
    "  false_neg = np.sum(cm, axis=1) - true_pos\n",
    "\n",
    "  precision = true_pos / (true_pos+false_pos)\n",
    "  recall = true_pos / (true_pos + false_neg)\n",
    "  \n",
    "  f1_score = 2/(precision**-1 + recall**-1)\n",
    "  return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0X1Sb6ia_Fm_"
   },
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "# gnb = GaussianNB()\n",
    "# clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "# clf = DT(max_depth =50, max_leaf_nodes=20, random_state=42)\n",
    "# clf = SVC(kernel= 'linear')\n",
    "\n",
    "M = 1\n",
    "N = 10\n",
    "# classifiers = ['linearSVM', 'knn', 'dt','nb', 'rf']\n",
    "# classifiers = ['linearSVM', 'knn', 'knn2', 'knn3', 'knn4', 'knn5', 'dt', 'rf']\n",
    "classifiers = ['linearSVM', 'knn', 'dt']\n",
    "labels = ['dataset', 'classifier', 'precision', 'recall', 'f1score', 'accuracy', 'selected_features', 'exec_time(sec)']\n",
    "# labels = ['dataset', 'classifier', 'precision', 'recall', 'f1score', 'accuracy', 'roc_auc_score', 'selected_features', 'exec_time(sec)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "N_F0NCA_LOjs",
    "outputId": "4a7715ca-7757-443a-9d88-9cd387dd0e27"
   },
   "outputs": [],
   "source": [
    "# # directory = \"../all dataset/csv dataset/sadia apu paper dataset\"\n",
    "# # directory = \"../all dataset/csv dataset/from suravi\"\n",
    "# # directory = \"../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format\"\n",
    "# # directory = \"../all dataset/csv dataset/Five dataset\"\n",
    "# # directory = \"../all dataset/csv dataset/GSE gene dataset\"\n",
    "# # directory = \"../all dataset/csv dataset/GDS gene dataset\"\n",
    "# # directory = \"../all dataset/csv dataset/Preprocessed_IDS_Datasets\"\n",
    "# directory = \"../../all dataset/csv dataset/Seleceted dataset\"\n",
    "\n",
    "# datasets = os.listdir(directory)\n",
    "\n",
    "# # datasets = os.listdir(directory)\n",
    "# # datasets.remove('Lung.csv')\n",
    "# # datasets.remove('colon.csv')\n",
    "# # datasets.remove('Semeion.csv')\n",
    "\n",
    "# # datasets = os.listdir(directory)\n",
    "# # datasets.remove('LUNG.csv')\n",
    "# # datasets.remove('MLL.csv')\n",
    "# # datasets.remove('OVARIAN.csv')\n",
    "\n",
    "# # datasets = ['awid_preprocessed.csv', 'unsw_nb15_preprocessed.csv', 'cic_ids2017_preprocessed.csv', 'kdd_cup99_preprocessed.csv']\n",
    "# # datasets = ['nsl_kdd_cat_in_num_binaryclass.csv']\n",
    "# # datasets = ['nsl_kdd_cat_in_num_multiclass.csv']\n",
    "# # datasets = ['unsw_nb_15_cat_in_num_binaryclass.csv']\n",
    "# # datasets = ['unsw_nb_15_cat_in_num_multiclass.csv']\n",
    "\n",
    "\n",
    "# # datasets = ['cic_ids_full_binaryclass.csv']\n",
    "# print(len(datasets),type(datasets), type(datasets[0]))\n",
    "# print (datasets)\n",
    "# # ['BLCA.csv', 'BRCA.csv', 'CESC.csv', 'LAML.csv', 'LIHC.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# per_dataset_result_storing_dir = \"new_method_base/\"\n",
    "# pickle_file_result_dir = \"new_method_base_pickle_files/\"\n",
    "# # cm = np.zeros((2,2))\n",
    "# derived_feature_dir = \"derived_feature_df/\"\n",
    "########################### FOR UCI DATASET ###############################\n",
    "csv_results = []\n",
    "def produce_result_with_robust_mahalanobis_distance_with_DT():\n",
    "  for dataset in datasets:\n",
    "#     linearSVM_result_list = []\n",
    "#     knn_result_list = []\n",
    "#     knn2_result_list = []\n",
    "#     knn3_result_list = []\n",
    "#     knn4_result_list = []\n",
    "#     knn5_result_list = []\n",
    "    dt_result_list = []\n",
    "#     rf_result_list = []\n",
    "    \n",
    "#     ten_fold_feature_set =[]\n",
    "    ten_fold_accuracy = []\n",
    "#     ten_fold_feature_set_with_score =[]\n",
    "    print(\"##############################################\")\n",
    "    print (\"reading dataset: \",dataset)\n",
    "    dataset_file_name = dataset[:-4]\n",
    "    \n",
    "#     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/from suravi/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GDS gene dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GSE gene dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Preprocessed_IDS_Datasets/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Security_dataset/'+dataset\n",
    "    file_name = '../../all dataset/csv dataset/Seleceted dataset/'+dataset\n",
    "    \n",
    "    undiscretized_df = pd.read_csv (file_name)\n",
    "    print(\"##############################################\")\n",
    "\n",
    "    # print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "    # print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "    # print(undiscretized_df.head(3))\n",
    "    \n",
    "    undiscretized_df = get_df_for_dataset_except_single_value_column(undiscretized_df)\n",
    "\n",
    "    discretized_df = get_discritized_df(undiscretized_df)\n",
    "#     print(\"Discritized Dataframe \\n---------------------\")\n",
    "    print(discretized_df.shape, len(discretized_df.columns) )\n",
    "    # print(discretized_df.head(3))\n",
    "\n",
    "    X = discretized_df.drop(columns=['0'])\n",
    "    y = discretized_df['0']\n",
    "    # print (X.shape,y.shape, type(X), type(y))\n",
    "    # print(X.head(3))\n",
    "    # print(y.head(3))\n",
    "    \n",
    "    myfile.write( dataset + \"\\n\" )\n",
    "#     irrelevant_feature_storing_file.write( dataset + \"\\n\" )\n",
    "#     per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "    kf = StratifiedKFold(n_splits = 10, shuffle=True, random_state=10)\n",
    "#     kf = LeaveOneOut()\n",
    "    # print(kf.get_n_splits(discretized_df))\n",
    "    start_time = time.time() \n",
    "    selected_featutre_length_list =[]\n",
    "#     derived_list_of_no_of_features_in_each_cluster_file = open(derived_feature_dir+'/list_of_no_of_features_in_each_cluster_'+dataset_file_name + \".txt\",\"w+\")   \n",
    "#     list_of_no_of_features_in_each_cluster, derived_features_df = get_final_selected_features(discretized_df)\n",
    "#     robust_mean_list, inv_covmat_list, final_clusters = get_final_selected_features_with_robust_mahalanobis_distance_with_actual_value(discretized_df, undiscretized_df)    \n",
    "#     derived_features_df.to_csv (derived_feature_dir+'/derived_'+dataset_file_name+'.csv', sep=\",\", index=None)\n",
    "#     derived_list_of_no_of_features_in_each_cluster_file.write(str(list_of_no_of_features_in_each_cluster))\n",
    "#     print(\"shape check -->> \", len(list_of_no_of_features_in_each_cluster), derived_features_df.shape)\n",
    "#     print(\"list_of_no_of_features_in_each_cluster\\n\", list_of_no_of_features_in_each_cluster)\n",
    "    \n",
    "    n_class = len(undiscretized_df['0'].unique())\n",
    "    cm = np.zeros((n_class,n_class))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "      one_fold_exec_start_time = time.time()\n",
    "      print(\"==========================================\")\n",
    "      # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "      undiscretized_X_train, undiscretized_X_test = undiscretized_df.drop(columns=['0']).iloc[train_index], undiscretized_df.drop(columns=['0']).iloc[test_index]\n",
    "      undiscretized_y_train, undiscretized_y_test = undiscretized_df['0'].iloc[train_index], undiscretized_df['0'].iloc[test_index]\n",
    "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "      # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "      # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "    \n",
    "      one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "      one_fold_train_undiscretized_df = pd.concat([undiscretized_y_train, undiscretized_X_train], axis=1)\n",
    "      one_fold_test_undiscretized_df = pd.concat([undiscretized_y_test, undiscretized_X_test], axis=1)\n",
    "#       print(\"one_fold_discretized_df col \", one_fold_discretized_df.shape, one_fold_discretized_df.columns)\n",
    "#       print(\"one_fold_train_undiscretized_df col \", one_fold_train_undiscretized_df.shape, one_fold_train_undiscretized_df.columns)\n",
    "#       print(\"one_fold_test_undiscretized_df col \", one_fold_test_undiscretized_df.shape,  one_fold_test_undiscretized_df.columns)\n",
    "    \n",
    "      robust_mean_list, inv_covmat_list, final_clusters = get_final_selected_features_with_robust_mahalanobis_distance_with_actual_value(one_fold_discretized_df, one_fold_train_undiscretized_df)\n",
    "      print(\"RMD for train data is calculating -->>\")\n",
    "      train_list_of_no_of_features_in_each_cluster, train_derived_features_df = get_derived_features_using_robust_mahalanobis_distance(one_fold_train_undiscretized_df, final_clusters, robust_mean_list, inv_covmat_list)\n",
    "      print(\"RMD for test data is calculating -->>\")\n",
    "      test_list_of_no_of_features_in_each_cluster, test_derived_features_df = get_derived_features_using_robust_mahalanobis_distance(one_fold_test_undiscretized_df, final_clusters, robust_mean_list, inv_covmat_list)\n",
    "#       print(\"length of train_list_of_no_of_features_in_each_cluster and train shape \", len(train_list_of_no_of_features_in_each_cluster), train_derived_features_df.shape)\n",
    "#       print(\"length of test_list_of_no_of_features_in_each_cluster and train shape \", len(test_list_of_no_of_features_in_each_cluster), test_derived_features_df.shape)\n",
    "#       print(\"original train and test data shape \", undiscretized_X_train.shape, undiscretized_X_test.shape)\n",
    "      print(\"test_list_of_no_of_features_in_each_cluster\\n\", test_list_of_no_of_features_in_each_cluster)\n",
    "      selected_featutre_length_list.append(len(final_clusters))\n",
    "      \n",
    "      X_train, X_test = train_derived_features_df.values.astype(float), test_derived_features_df.values.astype(float)\n",
    "      y_train, y_test = undiscretized_y_train.values.astype(int), undiscretized_y_test.values.astype(int)\n",
    "    \n",
    "#       clf = DT(random_state = 42) \n",
    "      clf = SVC(kernel= 'linear', probability = True)\n",
    "      clf.fit(X_train, y_train)\n",
    "      Predictions_test = clf.predict(X_test)\n",
    "      true = list(y_test)\n",
    "      pred = list(Predictions_test)\n",
    "      precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "      accuracy = accuracy_score(true, pred)\n",
    "      dt_result_list.append([precision,recall,f1score,accuracy])\n",
    "\n",
    "#       cm += confusion_matrix(true, pred)\n",
    "#       print(cm)\n",
    "        \n",
    "#         pred_prob = clf.predict_proba(X_test)\n",
    "#         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "\n",
    "      one_fold_exec_end_time = time.time()\n",
    "      one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time\n",
    "    \n",
    "      print(\"\\nDataset: \", dataset ,\", Classifier: DT, Fold: \", fold_no, \", Derived selected features are: \", len(final_clusters), \", Execution time \", one_fold_exec_time_diff)\n",
    "      print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "#       print(\"Dataset: \"+ dataset + \", Derived selected features are: \"+ str(derived_features_df.shape[1])+ \", Execution time \"+ str(one_fold_exec_time_diff) +\"\\n\")\n",
    "#       myfile.write(\"Dataset: \"+ dataset + \", Derived selected features are: \"+ str(derived_features_df.shape[1])+ \", Execution time \"+ str(one_fold_exec_time_diff) +\"\\n\")\n",
    "#       myfile.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       feature_storing_file.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\" and selected features are -->>\\n\")\n",
    "#       per_fold_feature_storing_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       individual_file_all_fold_result_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       individual_file_all_fold_result_with_score_file.write( str(final_selected_feature_with_score_dic) + \"\\n\" )\n",
    "      ten_fold_accuracy.append([accuracy])\n",
    "      fold_no +=1\n",
    "    end_time = time.time()\n",
    "    time_diff = end_time - start_time\n",
    "    acc_result_df = pd.DataFrame(data=ten_fold_accuracy)\n",
    "    acc_result_df.to_csv (\"RMD_ten_fold_result (robust mean covariance with all normal and attack class data)/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    \n",
    "    dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "    average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    \n",
    "    print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "    print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "    print(\"On average selected features are: \", average_selected_feature)\n",
    "    print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "    print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "#     csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], dt_result[2], \"{:.2f}\".format(dt_result[3]*100), average_selected_feature, time_diff])\n",
    "    csv_results.append([dataset, \"SVM\", dt_result[0], dt_result[1], dt_result[2], \"{:.2f}\".format(dt_result[3]*100), average_selected_feature, time_diff])\n",
    "    \n",
    "#     dataset_ten_fold_feature_set_dic[dataset] = ten_fold_feature_set\n",
    "#     pickle.dump(ten_fold_feature_set, pickle_file_result)\n",
    "#     pickle.dump(ten_fold_feature_set_with_score, pickle_file_result)\n",
    "#     pickle_file_result.close()\n",
    "       \n",
    "#   myfile.write( \"\\n\\n\"+ str(dataset_ten_fold_feature_set_dic))\n",
    "#   return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # FOR DT\n",
    "# # datasets = ['iris.csv', 'balance.csv', 'mammographic.csv', 'newthyroid.csv', 'phoneme.csv','appendicitis.csv','ecoli3.csv','pima-indians-diabetes.csv','shuttle.csv','wisconsin.csv','magic.csv','page-blocks.csv','winequality-white.csv','cleveland.csv','heart.csv','wine.csv','penbased.csv','vehicle0.csv','hepatitis.csv','waveform.csv','thyroid.csv','Parkinsons.csv','steel.csv','ionosphere.csv','landsat.csv','texture.csv','spectfheart.csv','optdigits.csv', 'coil2000.csv', 'movement_libras.csv']\n",
    "# # datasets = ['winequality-white.csv','cleveland.csv','heart.csv','wine.csv','penbased.csv','vehicle0.csv','hepatitis.csv','waveform.csv','thyroid.csv','Parkinsons.csv','steel.csv','ionosphere.csv','landsat.csv','texture.csv','spectfheart.csv','optdigits.csv', 'coil2000.csv', 'movement_libras.csv']\n",
    "# # not done\n",
    "# # datasets =['steel.csv']\n",
    "# # datasets = ['ionosphere.csv','landsat.csv']\n",
    "# # not done\n",
    "# # datasets = ['texture.csv']\n",
    "# # datasets = ['spectfheart.csv','optdigits.csv', 'coil2000.csv', 'movement_libras.csv']\n",
    "\n",
    "# # FOR SVM\n",
    "# # datasets = ['iris.csv', 'balance.csv', 'mammographic.csv', 'newthyroid.csv', 'phoneme.csv','appendicitis.csv','ecoli3.csv','pima-indians-diabetes.csv','wisconsin.csv','page-blocks.csv','winequality-white.csv','cleveland.csv','heart.csv','wine.csv','vehicle0.csv','hepatitis.csv','waveform.csv','thyroid.csv','Parkinsons.csv','ionosphere.csv','landsat.csv','spectfheart.csv','optdigits.csv', 'movement_libras.csv']\n",
    "# # datasets = ['iris.csv', 'balance.csv', 'mammographic.csv', 'newthyroid.csv', 'phoneme.csv','appendicitis.csv','ecoli3.csv','pima-indians-diabetes.csv','wisconsin.csv']\n",
    "# # datasets = ['cleveland.csv','heart.csv','wine.csv','vehicle0.csv','hepatitis.csv','waveform.csv','thyroid.csv','Parkinsons.csv','ionosphere.csv','landsat.csv','spectfheart.csv','optdigits.csv', 'movement_libras.csv']\n",
    "# # not done\n",
    "# datasets = ['shuttle.csv','magic.csv','page-blocks.csv','winequality-white.csv','penbased.csv','coil2000.csv']\n",
    "# produce_result_with_robust_mahalanobis_distance_with_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "# # result_df.to_csv ('RHC RMD (DT).csv', sep=\",\", index=None)\n",
    "# result_df.to_csv ('RHC RMD (SVM).csv', sep=\",\", index=None)\n",
    "# print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myfile.close()\n",
    "# irrelevant_feature_storing_file.close()\n",
    "# per_fold_feature_storing_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# per_dataset_result_storing_dir = \"new_method_base/\"\n",
    "# pickle_file_result_dir = \"new_method_base_pickle_files/\"\n",
    "# # cm = np.zeros((2,2))\n",
    "# derived_feature_dir = \"derived_feature_df/\"\n",
    "########################### FOR NETWORK DATASET ###############################\n",
    "csv_results = []\n",
    "def produce_result_with_robust_mahalanobis_distance_DT_with_CM():\n",
    "  for dataset in datasets:\n",
    "#     linearSVM_result_list = []\n",
    "#     knn_result_list = []\n",
    "#     knn2_result_list = []\n",
    "#     knn3_result_list = []\n",
    "#     knn4_result_list = []\n",
    "#     knn5_result_list = []\n",
    "    dt_result_list = []\n",
    "#     rf_result_list = []\n",
    "    \n",
    "#     ten_fold_feature_set =[]\n",
    "    ten_fold_accuracy = []\n",
    "#     ten_fold_feature_set_with_score =[]\n",
    "    print(\"##############################################\")\n",
    "    print (\"reading dataset: \",dataset)\n",
    "    dataset_file_name = dataset[:-4]\n",
    "    \n",
    "#     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/from suravi/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GDS gene dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GSE gene dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Preprocessed_IDS_Datasets/'+dataset\n",
    "    file_name = '../all dataset/csv dataset/Security_dataset/'+dataset\n",
    "    \n",
    "    undiscretized_df = pd.read_csv (file_name)\n",
    "    print(\"##############################################\")\n",
    "\n",
    "    # print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "    # print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "    # print(undiscretized_df.head(3))\n",
    "    \n",
    "    undiscretized_df = get_df_for_dataset_except_single_value_column(undiscretized_df)\n",
    "\n",
    "    discretized_df = get_discritized_df(undiscretized_df)\n",
    "#     print(\"Discritized Dataframe \\n---------------------\")\n",
    "    print(discretized_df.shape, len(discretized_df.columns) )\n",
    "    # print(discretized_df.head(3))\n",
    "\n",
    "    X = discretized_df.drop(columns=['0'])\n",
    "    y = discretized_df['0']\n",
    "    # print (X.shape,y.shape, type(X), type(y))\n",
    "    # print(X.head(3))\n",
    "    # print(y.head(3))\n",
    "    \n",
    "    myfile.write( dataset + \"\\n\" )\n",
    "#     irrelevant_feature_storing_file.write( dataset + \"\\n\" )\n",
    "#     per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "    kf = StratifiedKFold(n_splits = 10, shuffle=True, random_state=10)\n",
    "#     kf = LeaveOneOut()\n",
    "    # print(kf.get_n_splits(discretized_df))\n",
    "    start_time = time.time() \n",
    "    selected_featutre_length_list =[]\n",
    "#     derived_list_of_no_of_features_in_each_cluster_file = open(derived_feature_dir+'/list_of_no_of_features_in_each_cluster_'+dataset_file_name + \".txt\",\"w+\")   \n",
    "#     list_of_no_of_features_in_each_cluster, derived_features_df = get_final_selected_features(discretized_df)\n",
    "#     robust_mean_list, inv_covmat_list, final_clusters = get_final_selected_features_with_robust_mahalanobis_distance_with_actual_value(discretized_df, undiscretized_df)    \n",
    "#     derived_features_df.to_csv (derived_feature_dir+'/derived_'+dataset_file_name+'.csv', sep=\",\", index=None)\n",
    "#     derived_list_of_no_of_features_in_each_cluster_file.write(str(list_of_no_of_features_in_each_cluster))\n",
    "#     print(\"shape check -->> \", len(list_of_no_of_features_in_each_cluster), derived_features_df.shape)\n",
    "#     print(\"list_of_no_of_features_in_each_cluster\\n\", list_of_no_of_features_in_each_cluster)\n",
    "    \n",
    "    n_class = len(undiscretized_df['0'].unique())\n",
    "    cm = np.zeros((n_class,n_class))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "      one_fold_exec_start_time = time.time()\n",
    "      print(\"==========================================\")\n",
    "      # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "      undiscretized_X_train, undiscretized_X_test = undiscretized_df.drop(columns=['0']).iloc[train_index], undiscretized_df.drop(columns=['0']).iloc[test_index]\n",
    "      undiscretized_y_train, undiscretized_y_test = undiscretized_df['0'].iloc[train_index], undiscretized_df['0'].iloc[test_index]\n",
    "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "      # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "      # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "    \n",
    "      one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "      one_fold_train_undiscretized_df = pd.concat([undiscretized_y_train, undiscretized_X_train], axis=1)\n",
    "      one_fold_test_undiscretized_df = pd.concat([undiscretized_y_test, undiscretized_X_test], axis=1)\n",
    "#       print(\"one_fold_discretized_df col \", one_fold_discretized_df.shape, one_fold_discretized_df.columns)\n",
    "#       print(\"one_fold_train_undiscretized_df col \", one_fold_train_undiscretized_df.shape, one_fold_train_undiscretized_df.columns)\n",
    "#       print(\"one_fold_test_undiscretized_df col \", one_fold_test_undiscretized_df.shape,  one_fold_test_undiscretized_df.columns)\n",
    "    \n",
    "      robust_mean_list, inv_covmat_list, final_clusters = get_final_selected_features_with_robust_mahalanobis_distance_with_actual_value(one_fold_discretized_df, one_fold_train_undiscretized_df)\n",
    "      print(\"RMD for train data is calculating -->>\")\n",
    "      train_list_of_no_of_features_in_each_cluster, train_derived_features_df = get_derived_features_using_robust_mahalanobis_distance(one_fold_train_undiscretized_df, final_clusters, robust_mean_list, inv_covmat_list)\n",
    "      print(\"RMD for test data is calculating -->>\")\n",
    "      test_list_of_no_of_features_in_each_cluster, test_derived_features_df = get_derived_features_using_robust_mahalanobis_distance(one_fold_test_undiscretized_df, final_clusters, robust_mean_list, inv_covmat_list)\n",
    "#       print(\"length of train_list_of_no_of_features_in_each_cluster and train shape \", len(train_list_of_no_of_features_in_each_cluster), train_derived_features_df.shape)\n",
    "#       print(\"length of test_list_of_no_of_features_in_each_cluster and train shape \", len(test_list_of_no_of_features_in_each_cluster), test_derived_features_df.shape)\n",
    "#       print(\"original train and test data shape \", undiscretized_X_train.shape, undiscretized_X_test.shape)\n",
    "      print(\"test_list_of_no_of_features_in_each_cluster\\n\", test_list_of_no_of_features_in_each_cluster)\n",
    "      selected_featutre_length_list.append(len(final_clusters))\n",
    "      \n",
    "      X_train, X_test = train_derived_features_df.values.astype(float), test_derived_features_df.values.astype(float)\n",
    "      y_train, y_test = undiscretized_y_train.values.astype(int), undiscretized_y_test.values.astype(int)\n",
    "    \n",
    "      clf = DT(random_state = 42) \n",
    "      clf.fit(X_train, y_train)\n",
    "      Predictions_test = clf.predict(X_test)\n",
    "      true = list(y_test)\n",
    "      pred = list(Predictions_test)\n",
    "      precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "      accuracy = accuracy_score(true, pred)\n",
    "      dt_result_list.append([precision,recall,f1score,accuracy])\n",
    "\n",
    "      cm += confusion_matrix(true, pred)\n",
    "      print(cm)\n",
    "        \n",
    "#         pred_prob = clf.predict_proba(X_test)\n",
    "#         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "\n",
    "      one_fold_exec_end_time = time.time()\n",
    "      one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time\n",
    "    \n",
    "      print(\"\\nDataset: \", dataset ,\", Classifier: DT, Fold: \", fold_no, \", Derived selected features are: \", len(final_clusters), \", Execution time \", one_fold_exec_time_diff)\n",
    "      print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "#       print(\"Dataset: \"+ dataset + \", Derived selected features are: \"+ str(derived_features_df.shape[1])+ \", Execution time \"+ str(one_fold_exec_time_diff) +\"\\n\")\n",
    "#       myfile.write(\"Dataset: \"+ dataset + \", Derived selected features are: \"+ str(derived_features_df.shape[1])+ \", Execution time \"+ str(one_fold_exec_time_diff) +\"\\n\")\n",
    "#       myfile.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       feature_storing_file.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\" and selected features are -->>\\n\")\n",
    "#       per_fold_feature_storing_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       individual_file_all_fold_result_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       individual_file_all_fold_result_with_score_file.write( str(final_selected_feature_with_score_dic) + \"\\n\" )\n",
    "      ten_fold_accuracy.append([accuracy])\n",
    "      fold_no +=1\n",
    "    end_time = time.time()\n",
    "    time_diff = end_time - start_time\n",
    "    acc_result_df = pd.DataFrame(data=ten_fold_accuracy)\n",
    "    acc_result_df.to_csv (\"RMD_ten_fold_result (robust mean covariance with all normal and attack class data)/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    \n",
    "    dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "    average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    \n",
    "    print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "    print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "    print(\"On average selected features are: \", average_selected_feature)\n",
    "    print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "    print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "#     csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], dt_result[2], \"{:.2f}\".format(dt_result[3]*100), average_selected_feature, time_diff])\n",
    "  \n",
    "#     dataset_ten_fold_feature_set_dic[dataset] = ten_fold_feature_set\n",
    "#     pickle.dump(ten_fold_feature_set, pickle_file_result)\n",
    "#     pickle.dump(ten_fold_feature_set_with_score, pickle_file_result)\n",
    "#     pickle_file_result.close()\n",
    "       \n",
    "#   myfile.write( \"\\n\\n\"+ str(dataset_ten_fold_feature_set_dic))\n",
    "  return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# per_dataset_result_storing_dir = \"new_method_base/\"\n",
    "# pickle_file_result_dir = \"new_method_base_pickle_files/\"\n",
    "# # cm = np.zeros((2,2))\n",
    "# derived_feature_dir = \"derived_feature_df/\"\n",
    "########################### FOR NETWORK DATASET with attack class accuracy###############################\n",
    "csv_results = []\n",
    "def produce_result_with_robust_mahalanobis_distance_DT_with_CM_with_attack_class_accuracy():\n",
    "  for dataset in datasets:\n",
    "#     linearSVM_result_list = []\n",
    "#     knn_result_list = []\n",
    "#     knn2_result_list = []\n",
    "#     knn3_result_list = []\n",
    "#     knn4_result_list = []\n",
    "#     knn5_result_list = []\n",
    "    dt_result_list = []\n",
    "#     rf_result_list = []\n",
    "    \n",
    "#     ten_fold_feature_set =[]\n",
    "    ten_fold_accuracy = []\n",
    "#     ten_fold_feature_set_with_score =[]\n",
    "    print(\"##############################################\")\n",
    "    print (\"reading dataset: \",dataset)\n",
    "    dataset_file_name = dataset[:-4]\n",
    "    \n",
    "#     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/from suravi/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GDS gene dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GSE gene dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Preprocessed_IDS_Datasets/'+dataset\n",
    "    file_name = '../../all dataset/csv dataset/Security_dataset/'+dataset\n",
    "#     file_name = '../../all dataset/csv dataset/Seleceted dataset/'+dataset\n",
    "    \n",
    "    undiscretized_df = pd.read_csv (file_name)\n",
    "    print(\"##############################################\")\n",
    "\n",
    "    # print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "    # print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "    # print(undiscretized_df.head(3))\n",
    "    \n",
    "    undiscretized_df = get_df_for_dataset_except_single_value_column(undiscretized_df)\n",
    "\n",
    "    discretized_df = get_discritized_df(undiscretized_df)\n",
    "#     print(\"Discritized Dataframe \\n---------------------\")\n",
    "    print(discretized_df.shape, len(discretized_df.columns) )\n",
    "    # print(discretized_df.head(3))\n",
    "\n",
    "    X = discretized_df.drop(columns=['0'])\n",
    "    y = discretized_df['0']\n",
    "    # print (X.shape,y.shape, type(X), type(y))\n",
    "    # print(X.head(3))\n",
    "    # print(y.head(3))\n",
    "    \n",
    "    myfile.write( dataset + \"\\n\" )\n",
    "#     irrelevant_feature_storing_file.write( dataset + \"\\n\" )\n",
    "#     per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "    kf = StratifiedKFold(n_splits = 10, shuffle=True, random_state=10)\n",
    "#     kf = LeaveOneOut()\n",
    "    # print(kf.get_n_splits(discretized_df))\n",
    "    start_time = time.time() \n",
    "    selected_featutre_length_list =[]\n",
    "    attack_accuracies_list = []\n",
    "#     derived_list_of_no_of_features_in_each_cluster_file = open(derived_feature_dir+'/list_of_no_of_features_in_each_cluster_'+dataset_file_name + \".txt\",\"w+\")   \n",
    "#     list_of_no_of_features_in_each_cluster, derived_features_df = get_final_selected_features(discretized_df)\n",
    "#     robust_mean_list, inv_covmat_list, final_clusters = get_final_selected_features_with_robust_mahalanobis_distance_with_actual_value(discretized_df, undiscretized_df)    \n",
    "#     derived_features_df.to_csv (derived_feature_dir+'/derived_'+dataset_file_name+'.csv', sep=\",\", index=None)\n",
    "#     derived_list_of_no_of_features_in_each_cluster_file.write(str(list_of_no_of_features_in_each_cluster))\n",
    "#     print(\"shape check -->> \", len(list_of_no_of_features_in_each_cluster), derived_features_df.shape)\n",
    "#     print(\"list_of_no_of_features_in_each_cluster\\n\", list_of_no_of_features_in_each_cluster)\n",
    "    \n",
    "    n_class = len(undiscretized_df['0'].unique())\n",
    "    cm = np.zeros((n_class,n_class))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "      one_fold_exec_start_time = time.time()\n",
    "      print(\"==========================================\")\n",
    "      # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "      undiscretized_X_train, undiscretized_X_test = undiscretized_df.drop(columns=['0']).iloc[train_index], undiscretized_df.drop(columns=['0']).iloc[test_index]\n",
    "      undiscretized_y_train, undiscretized_y_test = undiscretized_df['0'].iloc[train_index], undiscretized_df['0'].iloc[test_index]\n",
    "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "      # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "      # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "    \n",
    "      one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "      one_fold_train_undiscretized_df = pd.concat([undiscretized_y_train, undiscretized_X_train], axis=1)\n",
    "      one_fold_test_undiscretized_df = pd.concat([undiscretized_y_test, undiscretized_X_test], axis=1)\n",
    "#       print(\"one_fold_discretized_df col \", one_fold_discretized_df.shape, one_fold_discretized_df.columns)\n",
    "#       print(\"one_fold_train_undiscretized_df col \", one_fold_train_undiscretized_df.shape, one_fold_train_undiscretized_df.columns)\n",
    "#       print(\"one_fold_test_undiscretized_df col \", one_fold_test_undiscretized_df.shape,  one_fold_test_undiscretized_df.columns)\n",
    "    \n",
    "      robust_mean_list, inv_covmat_list, final_clusters = get_final_selected_features_with_robust_mahalanobis_distance_with_actual_value(one_fold_discretized_df, one_fold_train_undiscretized_df)\n",
    "      print(\"RMD for train data is calculating -->>\")\n",
    "      train_list_of_no_of_features_in_each_cluster, train_derived_features_df = get_derived_features_using_robust_mahalanobis_distance(one_fold_train_undiscretized_df, final_clusters, robust_mean_list, inv_covmat_list)\n",
    "      print(\"RMD for test data is calculating -->>\")\n",
    "      test_list_of_no_of_features_in_each_cluster, test_derived_features_df = get_derived_features_using_robust_mahalanobis_distance(one_fold_test_undiscretized_df, final_clusters, robust_mean_list, inv_covmat_list)\n",
    "#       print(\"length of train_list_of_no_of_features_in_each_cluster and train shape \", len(train_list_of_no_of_features_in_each_cluster), train_derived_features_df.shape)\n",
    "#       print(\"length of test_list_of_no_of_features_in_each_cluster and train shape \", len(test_list_of_no_of_features_in_each_cluster), test_derived_features_df.shape)\n",
    "#       print(\"original train and test data shape \", undiscretized_X_train.shape, undiscretized_X_test.shape)\n",
    "      print(\"test_list_of_no_of_features_in_each_cluster\\n\", test_list_of_no_of_features_in_each_cluster)\n",
    "      selected_featutre_length_list.append(len(final_clusters))\n",
    "      \n",
    "      X_train, X_test = train_derived_features_df.values.astype(float), test_derived_features_df.values.astype(float)\n",
    "      y_train, y_test = undiscretized_y_train.values.astype(int), undiscretized_y_test.values.astype(int)\n",
    "    \n",
    "      clf = DT(random_state = 42) \n",
    "      clf.fit(X_train, y_train)\n",
    "      Predictions_test = clf.predict(X_test)\n",
    "        \n",
    "      #### attack class accuracy ########\n",
    "      searchval = 0     ##### Normal class ID\n",
    "      attack_indexes = np.where(y_test != searchval)[0]\n",
    "      attack_accuracy = np.sum(Predictions_test[attack_indexes] == y_test[attack_indexes])/ len(attack_indexes)\n",
    "      print(np.sum(Predictions_test[attack_indexes] == y_test[attack_indexes]), \"/\", len(attack_indexes), \"=\",attack_accuracy )\n",
    "      print(\"normal indices length \", len(np.where(y_test == searchval)[0]))\n",
    "      print(\"attack indices length \", len(np.where(y_test != searchval)[0]))\n",
    "      attack_accuracies_list.append(attack_accuracy)\n",
    "    \n",
    "      true = list(y_test)\n",
    "      pred = list(Predictions_test)\n",
    "      precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "      accuracy = accuracy_score(true, pred)\n",
    "      dt_result_list.append([precision,recall,f1score,accuracy])\n",
    "\n",
    "      cm += confusion_matrix(true, pred)\n",
    "      print(cm)\n",
    "      \n",
    "        \n",
    "#         pred_prob = clf.predict_proba(X_test)\n",
    "#         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "\n",
    "      one_fold_exec_end_time = time.time()\n",
    "      one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time\n",
    "    \n",
    "      print(\"\\nDataset: \", dataset ,\", Classifier: DT, Fold: \", fold_no, \", Derived selected features are: \", len(final_clusters), \", Execution time \", one_fold_exec_time_diff)\n",
    "      print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "#       print(\"Dataset: \"+ dataset + \", Derived selected features are: \"+ str(derived_features_df.shape[1])+ \", Execution time \"+ str(one_fold_exec_time_diff) +\"\\n\")\n",
    "#       myfile.write(\"Dataset: \"+ dataset + \", Derived selected features are: \"+ str(derived_features_df.shape[1])+ \", Execution time \"+ str(one_fold_exec_time_diff) +\"\\n\")\n",
    "#       myfile.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       feature_storing_file.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\" and selected features are -->>\\n\")\n",
    "#       per_fold_feature_storing_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       individual_file_all_fold_result_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       individual_file_all_fold_result_with_score_file.write( str(final_selected_feature_with_score_dic) + \"\\n\" )\n",
    "      ten_fold_accuracy.append([accuracy])\n",
    "      fold_no +=1\n",
    "    end_time = time.time()\n",
    "    time_diff = end_time - start_time\n",
    "    acc_result_df = pd.DataFrame(data=ten_fold_accuracy)\n",
    "    acc_result_df.to_csv (\"RMD_ten_fold_result (robust mean covariance with all normal and attack class data)/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    \n",
    "    dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "    average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    average_attack_class_accuracy = np.mean(np.array(attack_accuracies_list))\n",
    "    \n",
    "    print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "    print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "    print(\"On average selected features are: \", average_selected_feature)\n",
    "    print(\"On average attack_class_accuracy is: \", average_attack_class_accuracy)\n",
    "    print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "    print(\"attack_accuracies_list \", attack_accuracies_list)\n",
    "    print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "#     csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], dt_result[2], \"{:.2f}\".format(dt_result[3]*100), average_selected_feature, time_diff])\n",
    "  \n",
    "#     dataset_ten_fold_feature_set_dic[dataset] = ten_fold_feature_set\n",
    "#     pickle.dump(ten_fold_feature_set, pickle_file_result)\n",
    "#     pickle.dump(ten_fold_feature_set_with_score, pickle_file_result)\n",
    "#     pickle_file_result.close()\n",
    "       \n",
    "#   myfile.write( \"\\n\\n\"+ str(dataset_ten_fold_feature_set_dic))\n",
    "  return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['nsl_kdd_cat_in_num_multiclass.csv']\n",
    "print(len(datasets),type(datasets), type(datasets[0]))\n",
    "print (datasets)\n",
    "dataset_file_name = datasets[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nsl_kdd_cat_in_num_multiclass\n",
    "print(\"nsl_kdd_cat_in_num_multiclass\")\n",
    "cm = produce_result_with_robust_mahalanobis_distance_DT_with_CM_with_attack_class_accuracy()\n",
    "print(np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Multiple class\n",
    "# nsl_kdd_cat_in_num_multiclass\n",
    "print(\"nsl_kdd_cat_in_num_multiclass\")\n",
    "class_prec, class_rec, class_f1 = classification_report(cm)\n",
    "class_acc = cm.diagonal()/np.sum(cm, axis=1)\n",
    "print('class-wise precision:',class_prec)\n",
    "print('class-wise recall:',class_rec)\n",
    "print('class-wise f1score:',class_f1)\n",
    "print('class-wise accuracy:',class_acc)\n",
    "print(cm.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "ov_FPR = np.sum(FP)/(np.sum(FP)+ np.sum(TN))\n",
    "\n",
    "print('class-wise False Positive Rate: ', FPR)\n",
    "print(\"OVERALL False Positive Rate: \", ov_FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_file_name)\n",
    "class_wise_result = []\n",
    "class_wise_result_label =['dataset', 'precision', 'recall', 'f1_score', 'accuracy', 'FPR']\n",
    "\n",
    "for index, val in enumerate(class_prec):\n",
    "  class_wise_result.append([dataset_file_name, \"{:.2f}\".format(class_prec[index]*100), \"{:.2f}\".format(class_rec[index]*100), \"{:.2f}\".format(class_f1[index]*100), \"{:.2f}\".format(class_acc[index]*100), FPR[index]])\n",
    "\n",
    "class_wise_result_df = pd.DataFrame(data=class_wise_result, columns = class_wise_result_label)\n",
    "class_wise_result_df.to_csv (\"RMD_class_wise_result (robust mean covariance with all normal and attack class data)/\"+ dataset_file_name +'_class_wise_result.csv', sep=\",\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = ['nsl_kdd_cat_in_num_binaryclass.csv']\n",
    "# print(len(datasets),type(datasets), type(datasets[0]))\n",
    "# print (datasets)\n",
    "# dataset_file_name = datasets[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # nsl_kdd_cat_in_num_binaryclass\n",
    "# print(\"nsl_kdd_cat_in_num_binaryclass\")\n",
    "# cm = produce_result_with_robust_mahalanobis_distance_DT_with_CM()\n",
    "# print(np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # nsl_kdd_cat_in_num_binaryclass\n",
    "# print(\"nsl_kdd_cat_in_num_binaryclass\")\n",
    "# class_prec, class_rec, class_f1 = classification_report(cm)\n",
    "# class_acc = cm.diagonal()/np.sum(cm, axis=1)\n",
    "# print('class-wise precision:',class_prec)\n",
    "# print('class-wise recall:',class_rec)\n",
    "# print('class-wise f1score:',class_f1)\n",
    "# print('class-wise accuracy:',class_acc)\n",
    "# print(cm.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "# FN = cm.sum(axis=1) - np.diag(cm)\n",
    "# TP = np.diag(cm)\n",
    "# TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# # Fall out or false positive rate\n",
    "# FPR = FP/(FP+TN)\n",
    "# ov_FPR = np.sum(FP)/(np.sum(FP)+ np.sum(TN))\n",
    "\n",
    "# print('class-wise False Positive Rate: ', FPR)\n",
    "# print(\"OVERALL False Positive Rate: \", ov_FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset_file_name)\n",
    "# class_wise_result = []\n",
    "# class_wise_result_label =['dataset', 'precision', 'recall', 'f1_score', 'accuracy', 'FPR']\n",
    "\n",
    "# for index, val in enumerate(class_prec):\n",
    "#   class_wise_result.append([dataset_file_name, \"{:.2f}\".format(class_prec[index]*100), \"{:.2f}\".format(class_rec[index]*100), \"{:.2f}\".format(class_f1[index]*100), \"{:.2f}\".format(class_acc[index]*100), FPR[index]])\n",
    "\n",
    "# class_wise_result_df = pd.DataFrame(data=class_wise_result, columns = class_wise_result_label)\n",
    "# class_wise_result_df.to_csv (\"RMD_class_wise_result (robust mean covariance with all normal and attack class data)/\"+ dataset_file_name +'_class_wise_result.csv', sep=\",\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['unsw_nb_15_cat_in_num_multiclass.csv']\n",
    "print(len(datasets),type(datasets), type(datasets[0]))\n",
    "print (datasets)\n",
    "dataset_file_name = datasets[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unsw_nb_15_cat_in_num_multiclass\n",
    "print(\"unsw_nb_15_cat_in_num_multiclass\")\n",
    "cm = produce_result_with_robust_mahalanobis_distance_DT_with_CM_with_attack_class_accuracy()\n",
    "print(np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multiple class\n",
    "# unsw_nb_15_cat_in_num_multiclass\n",
    "print(\"unsw_nb_15_cat_in_num_multiclass\")\n",
    "class_prec, class_rec, class_f1 = classification_report(cm)\n",
    "class_acc = cm.diagonal()/np.sum(cm, axis=1)\n",
    "print('class-wise precision:',class_prec)\n",
    "print('class-wise recall:',class_rec)\n",
    "print('class-wise f1score:',class_f1)\n",
    "print('class-wise accuracy:',class_acc)\n",
    "print(cm.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "ov_FPR = np.sum(FP)/(np.sum(FP)+ np.sum(TN))\n",
    "\n",
    "print('class-wise False Positive Rate: ', FPR)\n",
    "print(\"OVERALL False Positive Rate: \", ov_FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_file_name)\n",
    "class_wise_result = []\n",
    "class_wise_result_label =['dataset', 'precision', 'recall', 'f1_score', 'accuracy', 'FPR']\n",
    "\n",
    "for index, val in enumerate(class_prec):\n",
    "  class_wise_result.append([dataset_file_name, \"{:.2f}\".format(class_prec[index]*100), \"{:.2f}\".format(class_rec[index]*100), \"{:.2f}\".format(class_f1[index]*100), \"{:.2f}\".format(class_acc[index]*100), FPR[index]])\n",
    "\n",
    "class_wise_result_df = pd.DataFrame(data=class_wise_result, columns = class_wise_result_label)\n",
    "class_wise_result_df.to_csv (\"RMD_class_wise_result (robust mean covariance with all normal and attack class data)/\"+ dataset_file_name +'_class_wise_result.csv', sep=\",\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['cic_ids_full_multiclass.csv']\n",
    "print(len(datasets),type(datasets), type(datasets[0]))\n",
    "print (datasets)\n",
    "dataset_file_name = datasets[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cic_ids_full_multiclass\n",
    "print(\"cic_ids_full_multiclass\")\n",
    "cm = produce_result_with_robust_mahalanobis_distance_DT_with_CM_with_attack_class_accuracy()\n",
    "print(np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multiple class\n",
    "# cic_ids_full_multiclass\n",
    "print(\"cic_ids_full_multiclass\")\n",
    "class_prec, class_rec, class_f1 = classification_report(cm)\n",
    "class_acc = cm.diagonal()/np.sum(cm, axis=1)\n",
    "print('class-wise precision:',class_prec)\n",
    "print('class-wise recall:',class_rec)\n",
    "print('class-wise f1score:',class_f1)\n",
    "print('class-wise accuracy:',class_acc)\n",
    "print(cm.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "ov_FPR = np.sum(FP)/(np.sum(FP)+ np.sum(TN))\n",
    "\n",
    "print('class-wise False Positive Rate: ', FPR)\n",
    "print(\"OVERALL False Positive Rate: \", ov_FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_file_name)\n",
    "class_wise_result = []\n",
    "class_wise_result_label =['dataset', 'precision', 'recall', 'f1_score', 'accuracy', 'FPR']\n",
    "\n",
    "for index, val in enumerate(class_prec):\n",
    "  class_wise_result.append([dataset_file_name, \"{:.2f}\".format(class_prec[index]*100), \"{:.2f}\".format(class_rec[index]*100), \"{:.2f}\".format(class_f1[index]*100), \"{:.2f}\".format(class_acc[index]*100), FPR[index]])\n",
    "\n",
    "class_wise_result_df = pd.DataFrame(data=class_wise_result, columns = class_wise_result_label)\n",
    "class_wise_result_df.to_csv (\"RMD_class_wise_result (robust mean covariance with all normal and attack class data)/\"+ dataset_file_name +'_class_wise_result.csv', sep=\",\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = ['unsw_nb_15_cat_in_num_binaryclass.csv']\n",
    "# print(len(datasets),type(datasets), type(datasets[0]))\n",
    "# print (datasets)\n",
    "# dataset_file_name = datasets[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unsw_nb_15_cat_in_num_binaryclass\n",
    "# print(\"unsw_nb_15_cat_in_num_binaryclass\")\n",
    "# cm = produce_result_with_robust_mahalanobis_distance_DT_with_CM()\n",
    "# print(np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Binary class\n",
    "# # unsw_nb_15_cat_in_num_binaryclass\n",
    "# print(\"unsw_nb_15_cat_in_num_binaryclass\")\n",
    "# class_prec, class_rec, class_f1 = classification_report(cm)\n",
    "# class_acc = cm.diagonal()/np.sum(cm, axis=1)\n",
    "# print('class-wise precision:',class_prec)\n",
    "# print('class-wise recall:',class_rec)\n",
    "# print('class-wise f1score:',class_f1)\n",
    "# print('class-wise accuracy:',class_acc)\n",
    "# print(cm.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "# FN = cm.sum(axis=1) - np.diag(cm)\n",
    "# TP = np.diag(cm)\n",
    "# TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# # Fall out or false positive rate\n",
    "# FPR = FP/(FP+TN)\n",
    "# ov_FPR = np.sum(FP)/(np.sum(FP)+ np.sum(TN))\n",
    "\n",
    "# print('class-wise False Positive Rate: ', FPR)\n",
    "# print(\"OVERALL False Positive Rate: \", ov_FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset_file_name)\n",
    "# class_wise_result = []\n",
    "# class_wise_result_label =['dataset', 'precision', 'recall', 'f1_score', 'accuracy', 'FPR']\n",
    "\n",
    "# for index, val in enumerate(class_prec):\n",
    "#   class_wise_result.append([dataset_file_name, \"{:.2f}\".format(class_prec[index]*100), \"{:.2f}\".format(class_rec[index]*100), \"{:.2f}\".format(class_f1[index]*100), \"{:.2f}\".format(class_acc[index]*100), FPR[index]])\n",
    "\n",
    "# class_wise_result_df = pd.DataFrame(data=class_wise_result, columns = class_wise_result_label)\n",
    "# class_wise_result_df.to_csv (\"RMD_class_wise_result (robust mean covariance with all normal and attack class data)/\"+ dataset_file_name +'_class_wise_result.csv', sep=\",\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = ['cic_ids_full_binaryclass.csv']\n",
    "# print(len(datasets),type(datasets), type(datasets[0]))\n",
    "# print (datasets)\n",
    "# dataset_file_name = datasets[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cic_ids_full_binaryclass\n",
    "# print(\"cic_ids_full_binaryclass\")\n",
    "# cm = produce_result_with_robust_mahalanobis_distance_DT_with_CM()\n",
    "# print(np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Binary class\n",
    "# # cic_ids_full_binaryclass\n",
    "# print(\"cic_ids_full_binaryclass\")\n",
    "# class_prec, class_rec, class_f1 = classification_report(cm)\n",
    "# class_acc = cm.diagonal()/np.sum(cm, axis=1)\n",
    "# print('class-wise precision:',class_prec)\n",
    "# print('class-wise recall:',class_rec)\n",
    "# print('class-wise f1score:',class_f1)\n",
    "# print('class-wise accuracy:',class_acc)\n",
    "# print(cm.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "# FN = cm.sum(axis=1) - np.diag(cm)\n",
    "# TP = np.diag(cm)\n",
    "# TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# # Fall out or false positive rate\n",
    "# FPR = FP/(FP+TN)\n",
    "# ov_FPR = np.sum(FP)/(np.sum(FP)+ np.sum(TN))\n",
    "\n",
    "# print('class-wise False Positive Rate: ', FPR)\n",
    "# print(\"OVERALL False Positive Rate: \", ov_FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset_file_name)\n",
    "# class_wise_result = []\n",
    "# class_wise_result_label =['dataset', 'precision', 'recall', 'f1_score', 'accuracy', 'FPR']\n",
    "\n",
    "# for index, val in enumerate(class_prec):\n",
    "#   class_wise_result.append([dataset_file_name, \"{:.2f}\".format(class_prec[index]*100), \"{:.2f}\".format(class_rec[index]*100), \"{:.2f}\".format(class_f1[index]*100), \"{:.2f}\".format(class_acc[index]*100), FPR[index]])\n",
    "\n",
    "# class_wise_result_df = pd.DataFrame(data=class_wise_result, columns = class_wise_result_label)\n",
    "# class_wise_result_df.to_csv (\"RMD_class_wise_result (robust mean covariance with all normal and attack class data)/\"+ dataset_file_name +'_class_wise_result.csv', sep=\",\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "# result_df.to_csv (output_file_name+'.csv', sep=\",\", index=None)\n",
    "# print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myfile.close()\n",
    "# irrelevant_feature_storing_file.close()\n",
    "# per_fold_feature_storing_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {'0':[1, 0, 1, 2, 1, 0],\n",
    "#         '1':[3.841, 4.414, 4.778, 4.019, 7.046, 6.419],\n",
    "#         '2':[6.299, 5.893, 5.219, 5.836, 7.142, 7.641],\n",
    "#         '3':[12.814, 13.103, 11.92, 10.871, 13.235, 12.169] }\n",
    "  \n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# print(df.columns)\n",
    "# df.head(8)\n",
    "\n",
    "# true = df['0'].values\n",
    "# print(type(true), true)\n",
    "# pred = np.array([2, 0, 1, 2, 2, 1])\n",
    "# searchval = 0\n",
    "# attack_indexes = np.where(true != searchval)[0]\n",
    "# print(type(attack_indexes),attack_indexes)\n",
    "\n",
    "# print(pred[attack_indexes])\n",
    "# print(true[attack_indexes])\n",
    "# # attack_accuracy = sum(eq(pred_val1(attack_idx),ts_label(attack_idx)))/length(attack_idx);\n",
    "# attack_accuracy = np.sum(pred[attack_indexes] == true[attack_indexes])\n",
    "# print(attack_accuracy)\n",
    "# attack_accuracy = attack_accuracy/len(attack_indexes)\n",
    "# print(attack_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 1\n",
    "N = 10\n",
    "classifiers = ['linearSVM', 'knn', 'dt']\n",
    "labels = ['dataset', 'classifier', 'precision', 'recall', 'f1score', 'accuracy', 'selected_features', 'exec_time(sec)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## GENE and UCI DATASET RESULT ###########\n",
    "csv_results = []\n",
    "def produce_result_with_robust_mahalanobis_distance_svm_knn_DT():\n",
    "  for dataset in datasets:\n",
    "    linearSVM_result_list = []\n",
    "    knn_result_list = []\n",
    "#     knn2_result_list = []\n",
    "#     knn3_result_list = []\n",
    "#     knn4_result_list = []\n",
    "#     knn5_result_list = []\n",
    "    dt_result_list = []\n",
    "#     rf_result_list = []\n",
    "    \n",
    "#     ten_fold_feature_set =[]\n",
    "    ten_fold_accuracy_dt = []\n",
    "    ten_fold_accuracy_knn = []\n",
    "    ten_fold_accuracy_svm = []\n",
    "    ten_fold_fscore_dt = []\n",
    "    ten_fold_fscore_knn = []\n",
    "    ten_fold_fscore_svm = []\n",
    "#     ten_fold_feature_set_with_score =[]\n",
    "    print(\"##############################################\")\n",
    "    print (\"reading dataset: \",dataset)\n",
    "    dataset_file_name = dataset[:-4]\n",
    "    \n",
    "#     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/from suravi/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GDS gene dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GSE gene dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Preprocessed_IDS_Datasets/'+dataset\n",
    "#     file_name = '../../all dataset/csv dataset/Selected dataset/'+dataset\n",
    "    file_name = \"../../all dataset/csv dataset/Selected dataset/\"+dataset\n",
    "    \n",
    "    undiscretized_df = pd.read_csv (file_name)\n",
    "    print(\"##############################################\")\n",
    "\n",
    "    # print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "    # print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "    # print(undiscretized_df.head(3))\n",
    "    \n",
    "    undiscretized_df = get_df_for_dataset_except_single_value_column(undiscretized_df)\n",
    "\n",
    "    discretized_df = get_discritized_df(undiscretized_df)\n",
    "#     print(\"Discritized Dataframe \\n---------------------\")\n",
    "    print(discretized_df.shape, len(discretized_df.columns) )\n",
    "    # print(discretized_df.head(3))\n",
    "\n",
    "    X = discretized_df.drop(columns=['0'])\n",
    "    y = discretized_df['0']\n",
    "    # print (X.shape,y.shape, type(X), type(y))\n",
    "    # print(X.head(3))\n",
    "    # print(y.head(3))\n",
    "    \n",
    "    myfile.write( dataset + \"\\n\" )\n",
    "#     irrelevant_feature_storing_file.write( dataset + \"\\n\" )\n",
    "#     per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "    kf = StratifiedKFold(n_splits = 10, shuffle=True, random_state=10)\n",
    "    if (discretized_df.shape[0] <= 90):\n",
    "      print('LOOCV')\n",
    "      kf = LeaveOneOut()\n",
    "\n",
    "#     kf = LeaveOneOut()\n",
    "    # print(kf.get_n_splits(discretized_df))\n",
    "    start_time = time.time() \n",
    "    selected_featutre_length_list =[]\n",
    "#     derived_list_of_no_of_features_in_each_cluster_file = open(derived_feature_dir+'/list_of_no_of_features_in_each_cluster_'+dataset_file_name + \".txt\",\"w+\")   \n",
    "#     list_of_no_of_features_in_each_cluster, derived_features_df = get_final_selected_features(discretized_df)\n",
    "#     robust_mean_list, inv_covmat_list, final_clusters = get_final_selected_features_with_robust_mahalanobis_distance_with_actual_value(discretized_df, undiscretized_df)    \n",
    "#     derived_features_df.to_csv (derived_feature_dir+'/derived_'+dataset_file_name+'.csv', sep=\",\", index=None)\n",
    "#     derived_list_of_no_of_features_in_each_cluster_file.write(str(list_of_no_of_features_in_each_cluster))\n",
    "#     print(\"shape check -->> \", len(list_of_no_of_features_in_each_cluster), derived_features_df.shape)\n",
    "#     print(\"list_of_no_of_features_in_each_cluster\\n\", list_of_no_of_features_in_each_cluster)\n",
    "    \n",
    "    n_class = len(undiscretized_df['0'].unique())\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "      one_fold_exec_start_time = time.time()\n",
    "      print(\"==========================================\")\n",
    "      # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "      undiscretized_X_train, undiscretized_X_test = undiscretized_df.drop(columns=['0']).iloc[train_index], undiscretized_df.drop(columns=['0']).iloc[test_index]\n",
    "      undiscretized_y_train, undiscretized_y_test = undiscretized_df['0'].iloc[train_index], undiscretized_df['0'].iloc[test_index]\n",
    "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "      # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "      # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "    \n",
    "      one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "      one_fold_train_undiscretized_df = pd.concat([undiscretized_y_train, undiscretized_X_train], axis=1)\n",
    "      one_fold_test_undiscretized_df = pd.concat([undiscretized_y_test, undiscretized_X_test], axis=1)\n",
    "#       print(\"one_fold_discretized_df col \", one_fold_discretized_df.shape, one_fold_discretized_df.columns)\n",
    "#       print(\"one_fold_train_undiscretized_df col \", one_fold_train_undiscretized_df.shape, one_fold_train_undiscretized_df.columns)\n",
    "#       print(\"one_fold_test_undiscretized_df col \", one_fold_test_undiscretized_df.shape,  one_fold_test_undiscretized_df.columns)\n",
    "    \n",
    "      robust_mean_list, inv_covmat_list, final_clusters = get_final_selected_features_with_robust_mahalanobis_distance_with_actual_value(one_fold_discretized_df, one_fold_train_undiscretized_df)\n",
    "      print(\"RMD for train data is calculating -->>\")\n",
    "      train_list_of_no_of_features_in_each_cluster, train_derived_features_df = get_derived_features_using_robust_mahalanobis_distance(one_fold_train_undiscretized_df, final_clusters, robust_mean_list, inv_covmat_list)\n",
    "      print(\"RMD for test data is calculating -->>\")\n",
    "      test_list_of_no_of_features_in_each_cluster, test_derived_features_df = get_derived_features_using_robust_mahalanobis_distance(one_fold_test_undiscretized_df, final_clusters, robust_mean_list, inv_covmat_list)\n",
    "#       print(\"length of train_list_of_no_of_features_in_each_cluster and train shape \", len(train_list_of_no_of_features_in_each_cluster), train_derived_features_df.shape)\n",
    "#       print(\"length of test_list_of_no_of_features_in_each_cluster and train shape \", len(test_list_of_no_of_features_in_each_cluster), test_derived_features_df.shape)\n",
    "#       print(\"original train and test data shape \", undiscretized_X_train.shape, undiscretized_X_test.shape)\n",
    "      print(\"test_list_of_no_of_features_in_each_cluster\\n\", test_list_of_no_of_features_in_each_cluster)\n",
    "      selected_featutre_length_list.append(len(final_clusters))\n",
    "      \n",
    "      X_train, X_test = train_derived_features_df.values.astype(float), test_derived_features_df.values.astype(float)\n",
    "      y_train, y_test = undiscretized_y_train.values.astype(int), undiscretized_y_test.values.astype(int)\n",
    "    \n",
    "      for classifier_name in classifiers:\n",
    "        clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "        if (classifier_name == 'linearSVM'):\n",
    "          clf = SVC(kernel= 'linear', probability = True)\n",
    "#           clf = LinearSVC(penalty='l2', loss='hinge', C=1, random_state=42)\n",
    "        elif (classifier_name == 'knn'):\n",
    "          clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "        elif (classifier_name == 'knn2'):\n",
    "          clf = KNeighborsClassifier(n_neighbors=2, weights='uniform')\n",
    "        elif (classifier_name == 'knn3'):\n",
    "          clf = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "        elif (classifier_name == 'knn4'):\n",
    "          clf = KNeighborsClassifier(n_neighbors=4, weights='uniform')\n",
    "        elif (classifier_name == 'knn5'):\n",
    "          clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "        elif (classifier_name == 'dt'):\n",
    "          clf = DT(random_state = 42)\n",
    "        elif (classifier_name == 'rf'):\n",
    "          clf = RF(random_state = 42)\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        Predictions_test = clf.predict(X_test)\n",
    "        true = list(y_test)\n",
    "        pred = list(Predictions_test)\n",
    "        precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "        accuracy = accuracy_score(true, pred)\n",
    "        \n",
    "#         pred_prob = clf.predict_proba(X_test)\n",
    "#         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "        \n",
    "        if (classifier_name == 'linearSVM'):\n",
    "          linearSVM_result_list.append([precision,recall,f1score,accuracy])\n",
    "          ten_fold_accuracy_svm.append([accuracy])\n",
    "          ten_fold_fscore_svm.append([f1score])\n",
    "        elif (classifier_name == 'knn'):\n",
    "          knn_result_list.append([precision,recall,f1score,accuracy])\n",
    "          ten_fold_accuracy_knn.append([accuracy])\n",
    "          ten_fold_fscore_knn.append([f1score])\n",
    "        elif (classifier_name == 'knn2'):\n",
    "          knn2_result_list.append([precision,recall,f1score,accuracy])\n",
    "        elif (classifier_name == 'knn3'):\n",
    "          knn3_result_list.append([precision,recall,f1score,accuracy])\n",
    "        elif (classifier_name == 'knn4'):\n",
    "          knn4_result_list.append([precision,recall,f1score,accuracy])\n",
    "        elif (classifier_name == 'knn5'):\n",
    "          knn5_result_list.append([precision,recall,f1score,accuracy])\n",
    "        elif (classifier_name == 'dt'):\n",
    "          dt_result_list.append([precision,recall,f1score,accuracy])\n",
    "          ten_fold_accuracy_dt.append([accuracy])\n",
    "          ten_fold_fscore_dt.append([f1score])\n",
    "        elif (classifier_name == 'rf'):\n",
    "          rf_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         myfile.write(\"Dataset: \"+ dataset +\", Classifier: \"+ classifier_name +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\"\\n\")\n",
    "        print(\"\\nDataset: \", dataset ,\", Classifier: \", classifier_name ,\", Fold: \", fold_no, \", Extracted Features: \",len(final_clusters))\n",
    "        print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "\n",
    "#         pred_prob = clf.predict_proba(X_test)\n",
    "#         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "\n",
    "      one_fold_exec_end_time = time.time()\n",
    "      one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time\n",
    "      print(\"Fold: \", fold_no, \"Execution time \", one_fold_exec_time_diff)\n",
    "#       print(\"\\nDataset: \", dataset ,\", Classifier: \", classifier_name , \", Fold: \", fold_no, \", Derived selected features are: \", len(final_clusters), \", Execution time \", one_fold_exec_time_diff)\n",
    "#       print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "#       ten_fold_accuracy.append([accuracy])\n",
    "      fold_no +=1\n",
    "    end_time = time.time()\n",
    "    time_diff = end_time - start_time\n",
    "    acc_result_df_svm = pd.DataFrame(data=ten_fold_accuracy_svm)\n",
    "    acc_result_df_knn = pd.DataFrame(data=ten_fold_accuracy_knn)\n",
    "    acc_result_df_dt = pd.DataFrame(data=ten_fold_accuracy_dt)\n",
    "    acc_result_df_svm.to_csv (\"ten_fold_result/accuracy/svm/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    acc_result_df_knn.to_csv (\"ten_fold_result/accuracy/knn/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    acc_result_df_dt.to_csv (\"ten_fold_result/accuracy/dt/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    \n",
    "    fscore_result_df_svm = pd.DataFrame(data=ten_fold_fscore_svm)\n",
    "    fscore_result_df_knn = pd.DataFrame(data=ten_fold_fscore_knn)\n",
    "    fscore_result_df_dt = pd.DataFrame(data=ten_fold_fscore_dt)\n",
    "    fscore_result_df_svm.to_csv (\"ten_fold_result/fscore/svm/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    fscore_result_df_knn.to_csv (\"ten_fold_result/fscore/knn/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    fscore_result_df_dt.to_csv (\"ten_fold_result/fscore/dt/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    \n",
    "    linearSVM_result = np.mean(np.array(linearSVM_result_list), axis=0)\n",
    "    knn_result = np.mean(np.array(knn_result_list), axis=0)\n",
    "#     knn2_result = np.mean(np.array(knn2_result_list), axis=0)\n",
    "#     knn3_result = np.mean(np.array(knn3_result_list), axis=0)\n",
    "#     knn4_result = np.mean(np.array(knn4_result_list), axis=0)\n",
    "#     knn5_result = np.mean(np.array(knn5_result_list), axis=0)\n",
    "    dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "#     rf_result = np.mean(np.array(rf_result_list), axis=0)\n",
    "    average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    \n",
    "    print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "    print(\"result of dataset: \", dataset,\" linearSVM_result \", linearSVM_result)\n",
    "    print(\"result of dataset: \", dataset,\" knn_result \", knn_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn2_result \", knn2_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn3_result \", knn3_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn4_result \", knn4_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn5_result \", knn5_result)\n",
    "    print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "#     print(\"result of dataset: \", dataset,\" rf_result \", rf_result)\n",
    "\n",
    "    print(\"On average selected features are: \", average_selected_feature)\n",
    "    print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "    print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "    myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "\n",
    "    csv_results.append([dataset, \"linearSVM\", linearSVM_result[0], linearSVM_result[1], \"{:.2f}\".format(linearSVM_result[2]*100), \"{:.2f}\".format(linearSVM_result[3]*100), average_selected_feature, time_diff])\n",
    "    csv_results.append([dataset, \"knn(k=1)\", knn_result[0], knn_result[1], \"{:.2f}\".format(knn_result[2]*100), \"{:.2f}\".format(knn_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=2)\", knn2_result[0], knn2_result[1], knn2_result[2], \"{:.3f}\".format(knn2_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=3)\", knn3_result[0], knn3_result[1], knn3_result[2], \"{:.3f}\".format(knn3_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=4)\", knn4_result[0], knn4_result[1], knn4_result[2], \"{:.3f}\".format(knn4_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=5)\", knn5_result[0], knn5_result[1], knn5_result[2], \"{:.3f}\".format(knn5_result[3]*100), average_selected_feature, time_diff])\n",
    "    csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], \"{:.2f}\".format(dt_result[2]*100), \"{:.2f}\".format(dt_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"RF\", rf_result[0], rf_result[1], rf_result[2], \"{:.3f}\".format(rf_result[3]*100), average_selected_feature, time_diff])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # datasets = ['iris.csv', 'balance.csv', 'mammographic.csv', 'appendicitis.csv', 'ecoli3.csv', 'led7digit.csv', 'pima-indians-diabetes.csv', 'wisconsin.csv', 'heart.csv', 'wine.csv', 'vehicle0.csv', 'hepatitis.csv', 'German.csv', 'thyroid.csv', 'dermatology_formatted.csv', 'landsat.csv', 'spectfheart.csv', 'Spambase.csv', 'sonar data lebel first10fold.csv', 'optdigits.csv', 'movement_libras.csv', 'madelon.csv']\n",
    "datasets = ['iris.csv', 'balance.csv', 'mammographic.csv', 'appendicitis.csv', 'ecoli3.csv', 'led7digit.csv', 'pima-indians-diabetes.csv', 'wisconsin.csv', 'heart.csv', 'wine.csv', 'vehicle0.csv', 'hepatitis.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "# result_df.to_csv ('RHC RMD (DT).csv', sep=\",\", index=None)\n",
    "result_df.to_csv ('RHC RMD svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = ['thyroid.csv', 'dermatology_formatted.csv', 'landsat.csv', 'spectfheart.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "# result_df.to_csv ('RHC RMD (DT).csv', sep=\",\", index=None)\n",
    "result_df.to_csv ('RHC RMD svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = ['sonar data lebel first10fold.csv', 'optdigits.csv', 'movement_libras.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "# result_df.to_csv ('RHC RMD (DT).csv', sep=\",\", index=None)\n",
    "result_df.to_csv ('RHC RMD svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = ['madelon.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "# result_df.to_csv ('RHC RMD (DT).csv', sep=\",\", index=None)\n",
    "result_df.to_csv ('RHC RMD svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = ['German.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "# result_df.to_csv ('RHC RMD (DT).csv', sep=\",\", index=None)\n",
    "result_df.to_csv ('RHC RMD svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['Spambase.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "# result_df.to_csv ('RHC RMD (DT).csv', sep=\",\", index=None)\n",
    "result_df.to_csv ('RHC RMD svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['COLON.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "result_df.to_csv ('RHC RMD svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['SRBCT.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "result_df.to_csv ('RHC RMD svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['LYMPHOMA.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "result_df.to_csv ('RHC RMD svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['CNS.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "result_df.to_csv ('RHC RMD svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['LEUKEMIA.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "result_df.to_csv ('RHC RMD svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['LEUKEMIA3C.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "result_df.to_csv ('RHC RMD svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['LEUKEMIA4C.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "result_df.to_csv ('RHC RMD svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = ['COLON.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = ['SRBCT.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = ['CNS.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = ['LYMPHOMA.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['LEUKEMIA.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['LEUKEMIA3C.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['LEUKEMIA4C.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "# result_df.to_csv ('RHC RMD (DT).csv', sep=\",\", index=None)\n",
    "result_df.to_csv ('RHC RMD svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()\n",
    "irrelevant_feature_storing_file.close()\n",
    "per_fold_feature_storing_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-DfHpF44AM8_"
   ],
   "name": "FAST minimum spanning tree_v2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
